
\status{Not written}

In this section we take the opportunity to improve on our work stealing
implementation from Section \ref{sec:rts_work_stealing}.
While we made these improvments we also found it useful to change how idle
engines behave.
Although these too changes are conceptually distinct,
they where made together and their implementations are interlinked.
Therefore we will present and benchmark them together as one set of changes.

\plan{Describe problems with associating stacks with contexts}
Sparks are stored on context local deques,
this has a several significant problems.

\begin{description}

    \item[There is a dynanic number of spark deques]~

    The number of contexts changes during a programs execution,
    therefore the number of spark deques also changes.
    This means that we must have code to manage this chaging number of
    deques.
    This code makes the runtime system more complicated necessary,
    both when stealing a spark and when destroying or creating a context.

    \item[This requires locking]~

    The management of contexts must be thread safe so that the set of
    spark deques is not currupted.
    We store spark deques in a global array protected by a lock.
    It may be possible to replace the array with a lock free datastructure.
    However it is better to remove the need of thread safty by using a
    constant set of deques.

    \item[A large number of contexts makes work stealing slower]~
    
    In previous sections
    we have shown that the number of contexts in use can often be very high,
    much higher than the number of Mercury engines.
    If there are $N$ engines and $M$ contexts,
    then there can be at most $N$ contexts running and
    at least $M-N$ contexts suspended (blocked and waiting to run),
    In some cases there can be at most $M-1$ suspended contexts.
    A context can become suspended in one of two ways:
    by blocking on a future's value in call to \wait,
    or by blocking on an incomplete conjunct in a call to \joinandcontinue.
    We attempt to minimise the former case and the later case cannot occur
    if the context has a spark on its local spark deque (it would run the
    spark rather than block).
    Therefore the large majority of the suspended contexts will not have
    sparks on their deques,
    and the probability of selecting a deque at random with a spark on its
    stack is only a little bit higher than $M \choose N$ at best and
    and $M \choose 1$ at worst.
    Furthermore the value of $M$ can be very high in pathological cases.
    If an engine does not successfully steal a spark from a deque,
    it will continue by trying to steal a spark from a different deque.
    An engine can exhaust all its attempts, even when there is work
    available.
    Upon exhausting all its attempts or all the deques,
    the engine will sleep before making another round of attempts.
    Each round of attempts (regardless of success or failure) has a
    complexity of $O(M)$.

\end{description}

\noindent
\plan{We associate stacks with engines}
The solution to all of these problems is to associate spark deques with
engines rather than with contexts.
A running Mercury program has a constant number of engines,
and therefore the number of spark deques will not vary.
This has allowed us to remove the code used to resize the deque array,
the array is filled in when the engines are created during startup,
after which it is never modified.
This code is much simpler as it never needs to resize the array.
Context creation and distruction is now simpler and faster,
it does not need to use the spark array at all, and certainly never contends
for the spark array lock.
We can also remove the locking code in \trystealspark used to ensure that
the array is not changed while a thief is trying to steal a spark.
The cost of work stealing also becomes linear in the number of engines
rather than the number of contexts (there are usually fewer engines than
contexts).

\begin{algorithm}
\begin{algorithmic}[1]
\Procedure{try\_steal\_spark}{$spark\_ptr$}
  \State $result \gets false$
  \For{$attempt = 0$ to $MR\_num\_engines$}
    \State $victim\_index \gets
        (MR\_engine.victim\_counter + attempt) \bmod MR\_num\_engines$
    \State $deque \gets
       MR\_spark\_deques$[$victim\_index$]
    \State $result \gets$ steal\_spark($deque$, $spark\_ptr$)
    \If{$result$}
      \State break
    \EndIf
  \EndFor
  \State $MR\_engine.victim\_counter \gets
    MR\_engine.victim\_counter + offset$
  \State \Return $result$
\EndProcedure
\end{algorithmic}
\caption{try\_steal\_spark}
\label{alg:try_steal_spark_revised}
\end{algorithm}

\plan{Show new \trystealspark}
We have made some other changes to \trystealspark,
its new code is shown in Algorithm \ref{alg:try_steal_spark_revised}.
The lock was also used to protect the victim counter,
ensuring that round robbin selection of the victim was maintained.
Now each engine independently performs its own round robin selection of the
victim using a new field \code{victim\_counter} in the engine structure.
We have not evaluated if this policy works better or worse,
even if it is worse,
it avoids the cost of a lock which is more significant.
The two other changes are minor,
we have removed the configurable limit of the number of work stealing
attempts per round,
and the test for null array slots has been removed as it is now unnecessary.

\plan{Show how this is safe.}
Associating the spark deques with engines can change the order in which
sparks are executed,
we have to ensure that the system is still deadlock free.
In the previous version
a context that is blocked on a call to \wait may contain sparks
which can only be accessed by a thief,
In the current version,
those sparks are now associated with the engine that the context was running
on,
and therefore that engine has the opportinuty to run those sparks by
retriving them from the hot end of its own deque.
If the engine attempts to axecute one of these sparks it will need a
context,
and the creation of a new context may exceed the context limit even though
the spark is being executed locally.
This is just one instance where an engine \emph{without a context}
may try to run a spark from its own deque,
in the previous version a context would always be available because sparks
where associated with contexts.

\begin{algorithm}
\begin{multicols}{2}

\parbox{\textwidth}{
\begin{algorithmic}
    \Procedure{MR\_idle}{}
        \State \tramp{try\_run\_context()}
        \State \tramp{try\_run\_local\_spark($NULL$)}
        \State \tramp{try\_steal\_spark($NULL$)}
        \Goto MR\_sleep
    \EndProcedure
\end{algorithmic}
}

\begin{minipage}{\textwidth}
\begin{verbatim}
#define TRAMPOLINE(call)        \\
    do {                        \\
        MR_Code *code;          \\
        code = (call);          \\
        if (code) {             \\
            goto code;          \\
        }                       \\
    } while(0)
\end{verbatim}
\end{minipage}

\end{multicols}
\caption{New \idle code}
\label{alg:idle_entry_point}
\end{algorithm}

\paul{Rename \getglobalwork throughout previous sections to \idle}.

An idle engine without a context calls \idle to acquire new work,
\idle's code is shown in Algorithm \ref{alg:idle_entry_point}.
\idle has changed sagnificantly,
many of its details shown in previous sections have been moved into C
functions,
these include:
\tryruncontext which tries to execute a suspended but runnable context;
\tryrunlocalspark which tries to run a spark from the top of the engine's
spark deque, possibly creating a new context for the spark;
and 
\trystealspark which was shown above in Algorithm
\ref{alg:try_steal_spark_revised}.
Because running a local spark may allocate a context and exceed the context
limit,
the engine must execute any suspended but runnable context instead.
Doing so is always permitted dispite the context limit.
Furthermore,
a context whose execution has already begin may make more parallel work
available creating sparks or signalling futures.
If the engine is able to run the context until the completion of its work
(until the contexts executes the \joinandcontinue barrier at the end of a
parallel conjunct)
then this may make the context available to execute a spark from the
engine's local spark queue.
Therefore we always try to run a context (using \tryruncontext)
before attempting to run a local spark (using \tryrunlocalspark).
Of course there will be cases when \tryruncontext fails and an engine
without a context then attempts to run a local spark.
To facilitate this, the context limit is not checked in \tryrunlocalspark
(it is still used in \trystealspark).

\idle is a hard coded Mercury procedure and it does not return control to
its caller,
therefore it continues execution by jumping to the code address of the next
thing to execute.
This can either be the resume address of a context,
the entry point of a spark,
or the Mercury procedure \sleep.
However
the C functions are used to find the next context or spark to execute,
if successful these C functions prepare the engine to execute the spark or
context and then return the address that the engine should execute.
they \emph{must} return rather than execute the spark or context directly so
that the C stack pointer has the same value that it did upon entering \idle.
\idle uses a \emph{trampoline}\footnote{
    Trampoline is an overloaded term in computer science.
    The reader may or may not agree with our use of this term.
    }
macro to jump to the returned code
address or fall through to the next instruction if the function returned
false.
If the idle engine cannot find a spark or context to execute then it jumps
to \sleep.

\begin{algorithm}
\begin{minipage}{\textwidth}
\begin{verbatim}
struct engine_sleep_sync {
    sem_t                               sleep_sem;
    sem_t                               wake_sem;
    volatile unsigned                   state;
    volatile unsigned                   action;
    union MR_engine_wake_action_data    action_data;
};

union MR_engine_wake_action_data {      
    MR_EngineId     worksteal_engine;
    MR_Context      *context;
};
\end{verbatim}

\begin{algorithmic}
    \Procedure{MR\_sleep}{}
        \Loop
            \State $eng\_data \gets MR\_engien\_sleep\_data$[$engine\_id$]
            \State $eng\_data.state \gets$ SLEEPING
            \State $sem\_wait(eng\_data.sleep_sem)$
            \Switch{$eng\_data.action$}
              \Case{ACTION\_SHUTDOWN}
                \State $\cdots$
              \EndCase
              \Case{ACTION\_RUN\_CONTEXT}
                \State $ctxt \gets eng\_data.action\_data.context$
                \State MR\_load\_context($ctxt$)
                \Goto $ctxt.resume\_label$
              \EndCase
              \Case{ACTION\_STEAL\_SPARK}
                \State $MR\_engine.victim\_counter \gets
                    eng\_data.action\_data.worksteal\_engine$ 
                \State \tramp{try\_steal\_spark(NULL)}
                \State \tramp{try\_run\_context}
                \State break
              \EndCase
              \Case{ACTION\_NONE}
                \State \tramp{try\_run\_context}
                \State \tramp{try\_steal\_spark(NULL)}
                \State break
              \EndCase
            \EndSwitch
        \EndLoop
    \EndProcedure
\end{algorithmic}

\end{minipage}
\caption{The \sleep code}
\end{algorithm}

\sleep is another hand written Mercury procedure.
It uses an an
\code{engine\_sleep\_sync} structure to manage the state of each engine.
These structure are organized into a global array indesed by engine ids,
making them accessable to other engines.
The structure contains two semaphores;
the engine owning the structure will wait on \code{sleep\_sem} when it is
idle and has found no work,
meanwhile \code{wake\_sem} is used by other enignes to cotrol their mutual
access to the \enginesleepsync structure.
There are three other fields in the structure:
\code{state} is used by the engine that owns the structure to communicate
its state to other enignes,
\code{action} and \code{action\_data} are used by other threads when
communicating to this engine.

Upon jumping into \idle an enigne sets its state to \code{SLEEPING} and
waits on \code{sleep\_sem}.
If another engine posts to \code{sleep\_sem} then the engine is woken up,
and retrives the value of the \code{action} field.
This field can be used to tell the engine what to do upon wakeing.
It may be instructed to shutdown, to execute a context or to steal a spark.
If it is instructed to run a context it can be passed the context directly
using the \code{action\_data} field,
similarly, if it instructed to steal a spark \code{action\_data} will tell
it whose spark stack it should begin its round robin search from.



XXXXXXXXXXXXXXXXXXXXXXXX

If the engine attempts to execute one of these sparks it will need a
context.
At this point we have two choices,
the engine must either execute an existing suspended context,
or allocate a new context for a spark on its spark deque \emph{dispite} the
context limit.
It is best to attept to 
There may not always be a suspended context but if there is it should
eventually be executed to avoid a deadlock
(it may unblock a future that another context is blocked on).

It may also be optimal to execute suspended context,
since it may prevent the context limit from being exeeded.
But more importantly,
if the engine executed a spark,
and created a new context for the spark,
then that context might also block on a future,
this situation could loop, allocating more contexts dispite the context
limit.
Therefore this would not create a deadlock provided that an engine without a
context attempts to resume a suspended context before attempting to execute
one of its own sparks.

We have modified \getglobalwork to implement this,
now \getglobalwork attempts to run a suspended context,
then attempts to run a local spark and finally attempts to steal a spark
before going to sleep.
We took this opportunity to significantly change \getglobalwork,
we introduced a number of optimisations and fixed another problem.
When an engine fails to find any work and goes to sleep a timout is used to
wake it up.
This timeout defaults to 2ms.
When a context created a spark,
the idle engine would take an average of 1ms before attempting to steal the
spark.
If the context finished the first conjunct of a parallel conjunction it
would often take the task back off its deque before the thief stole it.
This results in sequential execution even though an idle engine was
available to run the spark.
Secondly,
using the timeout when there is no parallel work available is wasteful
as idle engines would wake up and needlessly attempt to steal work.
Therefore while modifying \getglobalwork we chose to remove the timeout,
we should instead notify sleeping engines of sparks, but this notification
should have a low cost.

%\begin{multicols}{2}



\begin{algorithm}
\parbox{\textwidth}{
\begin{algorithmic}
    \Procedure{MR\_idle\_dirty\_context}{}
        \State $join\_label \gets MR\_r1$
        \State \tramp{try\_run\_local\_spark($join\_label$)}
        \State \tramp{try\_steal\_spark($join\_label$)}
        \State save\_dirty\_context($join\_label$)
        \State \tramp{try\_run\_context()}
        \Goto MR\_sleep
    \EndProcedure
\end{algorithmic}
}
\caption{New entry point to the idle loop for dirty contexts.}
\end{algorithm}

\paul{Consider removing MR\_ from most if not all symbols.}

%\end{multicols}

\plan{Solution, wake engines for different types of work}
We modified the RTS so that waking an engine is easy, and it can be given a
message so that it knows where to look for work.

\plan{A lot of work went into preventing deadlocks due to race conditions,
a thread that is not yet sleeping if notified must wake up immediately.}

\plan{Show new \getglobalwork}
\plan{Show the algorithm for the new idle loop.}
Note that we execute contexts before sparks,
this is more-likely to produce futures and it may reduce memory consumption.

\plan{Extra benefit: when an engine is woken it can be told directly where
to find work, or be given the work directly.}

\plan{Extra benefit: we can be selective about which engine to wake,
while not implemented fully, we can wake a `nearby' engine so that
we can avoid communication between dies or sockets.}

\input{tab_work_stealing_revised}

\plan{Benchmark}

\plan{Evaluation}

\plan{Further potential work}

