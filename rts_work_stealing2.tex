
\status{Currently acting on feedback}

In this section we take the opportunity to improve on our work stealing
implementation from section \ref{sec:rts_work_stealing}.
While we made these improvements,
we also found it useful to change how idle engines behave.
Although these too changes are conceptually distinct,
they were made together and their implementations are interlinked.
Therefore we will present and benchmark them together as one set of changes.

\plan{Describe problems with associating stacks with contexts}
Sparks were originally stored on context local deques,
which has several significant problems.

\textbf{There is a dynamic number of spark deques.}
The number of contexts changes during a programs execution,
therefore the number of spark deques also changes.
This means that we must have code to manage this changing number of
deques.
This code makes the runtime system more complicated than necessary,
both when stealing a spark and when creating or destroying a context.

\textbf{Locking is required.}
The management of contexts must be thread safe so that the set of
spark deques is not corrupted.
We store spark deques in a global array protected by a lock.
It may be possible to replace the array with a lock free data structure.
However it is better to remove the need for thread safety by using a
constant set of deques.

\textbf{A large number of contexts makes work stealing slower.}
In prior sections
we have shown that the number of contexts in use can often be very high,
much higher than the number of Mercury engines.
If there are $N$ engines and $M$ contexts,
then there can be at most $N$ contexts running and
at least $M-N$ contexts suspended (blocked and waiting to run).
A context can become suspended in one of two ways:
by blocking on a future's value in a call to \wait,
or by blocking on an incomplete conjunct in a call to \joinandcontinue.
We attempt to minimise the former case (see chapter \ref{chap:overlap})
and the latter case cannot occur
if the context has a spark on its local spark deque (it would run the
spark rather than block).
Therefore the large majority of the suspended contexts will not have
sparks on their deques,
and the probability of selecting a deque at random with a spark on its
stack is only a little bit higher than $M \choose N$ at best and
$M \choose 1$ at worst.
Furthermore the value of $M$ can be very high in pathological cases.
If an engine does not successfully steal a spark from a deque,
it will continue by trying to steal a spark from a different deque.
An engine can exhaust all its attempts, even when there is work
available:
a spark may be placed on a deque after the engine has already attempted
to steal from it.
Upon exhausting all its attempts or all the deques,
the engine will sleep before making another round of attempts
(see \trystealspark in algorithm \ref{alg:try_steal_spark_initial} on
page \pageref{alg:try_steal_spark_initial}).
Each round of attempts (regardless of success or failure) has a
complexity of $O(M)$.

\plan{We associate stacks with engines}
The approach we have taken to solving these problems is based on associating
spark deques with engines rather than with contexts.
A running Mercury program has a constant number of engines,
and therefore the number of spark deques will not vary.
This allows us to remove the code used to resize the deque array,
the array is filled in when the engines are created during startup,
after which it is never modified.
This makes context creation and destruction much simpler.
It also removes the need for the lock protecting the global array of spark
deques.
We can also remove the locking code in \trystealspark
(whose original version was shown in algorithm
\ref{alg:try_steal_spark_initial})
which was used to
ensure that the array is not changed while a thief is trying to steal a
spark.
The cost of work stealing also becomes linear in the number of engines
rather than the number of contexts.

\begin{algorithm}[tbp]
\begin{algorithmic}[1]
\Procedure{MR\_try\_steal\_spark}{}
  \If{$\left(
          \begin{array}{l}
          (current\_context \neq \text{NULL})\, \vee \\
          (MR\_num\_outstanding\_contexts < MR\_max\_contexts) \\
          \end{array}
          \right)$}
    \For{$attempt = 0$ to $MR\_num\_engines - 1$}
      \State $victim\_index \gets
          (MR\_engine.victim\_counter + attempt) \bmod MR\_num\_engines$
      \If{MR\_steal\_spark($MR\_spark\_deques$[$victim\_index$],
          \text{\code{\&}}$spark$)}
        \State $MR\_engine.victim\_counter \gets
          MR\_engine.victim\_counter + attempt$
        \State MR\_prepare\_engine\_for\_spark($spark$, NULL)
        \State \Return $spark.resume$
      \EndIf
    \EndFor
  \EndIf
  \State \Return NULL
\EndProcedure
\end{algorithmic}
\caption{try\_steal\_spark}
\label{alg:try_steal_spark_revised}
\end{algorithm}

\begin{algorithm}[tbp]
\begin{algorithmic}
\Procedure{MR\_prepare\_engine\_for\_spark}{$spark$, $join\_label$}
    \If{$current\_context = \text{NULL}$}
        \State $ctxt \gets$ MR\_get\_free\_context()
        \If{$ctxt = \text{NULL}$}
            \State $ctxt \gets$ MR\_create\_context()
        \EndIf
        \State MR\_load\_context($ctxt$)
    \EndIf
    \State $MR\_parent\_sp \gets spark.parent\_sp$
    \State $ctxt.thread\_local\_mutables \gets
      spark.thread\_local\_mutables$
    \State \Return $spark.resume$
\EndProcedure
\end{algorithmic}
\caption{MR\_prepare\_engine\_for\_spark()}
\label{alg:prepare_engine_for_spark}
\end{algorithm}

\plan{Show new \trystealspark}
We have made some other changes to \trystealspark,
whose new code is shown in algorithm \ref{alg:try_steal_spark_revised}.
Previously \trystealspark required its caller to check that stealing a spark
would not exceed the context limit;
this check has been moved into \trystealspark (line 2).
Another change is that \trystealspark
will now call \prepareengineforspark (line 7)
which will load a context into the engine if it doesn't already have one.
(algorithm \ref{alg:prepare_engine_for_spark}).
Finally \trystealspark will return the address of the spark's code;
the caller will jump to this address,
if it is not NULL.

In the previous version the lock was also used to protect the victim
counter;
it ensured that round robin selection of the victim was maintained.
Now each engine independently performs its own round robin selection of the
victim using a new field \code{victim\_counter} in the engine structure.
We have not evaluated if this policy is an improvement.
However when compared with the improvement due to removing the lock and
potentially large number of spark deques,
any difference in performance due to the selection of victims will be
negligible.
The two other changes are minor:
we have removed the configurable limit of the number of work stealing
attempts per round,
and the test for null array slots has been removed;
both are now unnecessary.

\begin{algorithm}[tbp]
\begin{algorithmic}
    \Procedure{MR\_idle}{}
        \State $code\_ptr \gets$ MR\_try\_run\_context()
        \If{$code\_ptr \neq$ NULL}
            \Goto $code\_ptr$
        \EndIf
        \State $code\_ptr \gets$ MR\_try\_run\_local\_spark($NULL$)
        \If{$code\_ptr \neq$ NULL}
            \Goto $code\_ptr$
        \EndIf
        \State $code\_ptr \gets$ MR\_try\_steal\_spark()
        \If{$code\_ptr \neq$ NULL}
            \Goto $code\_ptr$
        \EndIf
        \Goto MR\_sleep
    \EndProcedure
\end{algorithmic}
\caption{New \idle code}
\label{alg:idle_entry_point}
\end{algorithm}

\begin{algorithm}[tbp]
\begin{algorithmic}
\Procedure{MR\_try\_run\_context}{}
    \State MR\_acquire\_lock($MR\_runqueue\_lock$)
    \State $ctxt \gets$ MR\_get\_runnable\_context()
    \State MR\_release\_lock($MR\_runqueue\_lock$)
    \If{$ctxt \neq$ NULL}
        \If{$current\_context \neq$ NULL}
            \State MR\_release\_context($current\_context$)
        \EndIf
        \State MR\_load\_context($ctxt$)
        \State $resume \gets ctxt.resume$
        \State $ctxt.resume \gets$ NULL
        \State \Return $resume$
    \Else
        \State \Return NULL
    \EndIf
\EndProcedure
\end{algorithmic}
\caption{MR\_try\_run\_context()}
\label{alg:try_run_context}
\end{algorithm}

\begin{algorithm}[tbp]
\begin{algorithmic}
\Procedure{MR\_try\_run\_local\_spark}{$join\_label$}
    \State $result \gets$ MR\_pop\_spark($this\_engine.spark\_deque$)
    \If{$result =$ NULL}
        \State \Return NULL
    \EndIf
    \If{$\left(
        \begin{array}{l}
            (current\_context \neq \text{NULL}) \wedge \\
            (join\_label \neq \text{NULL}) \wedge \\
            (spark.sync\_term.orig\_context \neq current\_context)
        \end{array}\right)$}
        \State MR\_push\_spark($this\_engine.spark\_deque$, $spark$)
        \State \Return NULL
    \EndIf
    \State MR\_prepare\_engine\_for\_spark($spark$, $join\_label$)
    \State \Return $spark.resume$
\EndProcedure
\end{algorithmic}
\caption{MR\_try\_run\_local\_spark()}
\label{alg:try_run_local_spark}
\end{algorithm}

We have also made changes to the code that \idle engines execute.
An idle engine with a context that is free (it can be used for any spark) or
without a context will call \idle to acquire new work.
\idle has changed significantly;
the new version is shown in algorithm \ref{alg:idle_entry_point}.
Three new C functions are now used to implement the details of \idle, these
are:
\tryruncontext, \tryrunlocalspark and \trystealspark.
They are separate C functions so that we can use them from procedures other
than \idle, such as \joinandcontinue below.
\idle always tries to find a runnable context before a local spark;
we believe that executing a context is optimal
as a context whose execution has already begun,
may make more parallel work available by creating sparks or signalling
futures.
Also if the context does not block then when it finishes its work it can be
used to execute a spark from the engine's local spark queue.
Checking for runnable contexts first also helps to avoid the creation of new
contexts before existing context's computations are finished.
This partially avoids deadlocks that can occur when the context limit is
exceeded:
executing a waiting context rather than attempting to create a new context
for a spark does not increase the number of contexts that exist.

If \idle cannot find a context to resume then it
will call \tryrunlocalspark.
If there is a spark to execute and the engine does not have a context,
a new one will be created.
We do this without checking the context limit;
this, combined with attempting to run contexts before sparks (above)
avoids deadlocks.
We ensure that the system can still make progress when the context limit is
exceeded by not checking the limit when executing a local spark.
For example,
a situation can occur when a context may block on
a future that can only be signalled by another computation that is currently
represented by a spark, and therefore the creation of a new context may be
necessary.
If we did not allow contexts to be created for local sparks then deadlocks
would be possible.
Not checking the context limit in \tryrunlocalspark does not usually cause
the number of contexts to rise:
local spark execution tends to be in depth first left to right order
(sequential order) and is unlikely to block contexts and create new
contexts.
As described above \trystealspark does check the context limit.
While the context limit is a work-around to prevent some worst case
behaviour,
it is still important to use scheduling policies that keep the number of
contexts low:
contexts consume significant amounts of memory and
the garbage collector spends time scanning that memory.
By reducing the number of contexts we can improve memory and time usage.

\idle is a hand written Mercury procedure and it does not return control to
its caller.
Instead it continues execution by jumping to the code address of the next
thing to execute.
such as the
the resume address of a context,
or the entry point of a spark.
if one of its callees such as \trystealspark where to make this jump rather
than returning and then letting \idle jump,
then this would leak the stack frames created for \trystealspark.
Therefore, each of the functions \tryrunlocalspark, \tryruncontext and
\trystealspark must return the address of the next thing to execute and
allow \idle to jump to this code or jump to \sleep.

\tryruncontext is shown in algorithm \ref{alg:try_run_context};
it attempts to take a context from the context runqueue while holding the
context runqueue lock.
Previously this lock protected all of \idle.
If \tryruncontext finds a context,
it first checks for and unloads the engine's current context,
and then loads the new context.
It clears the contexts resume field and then returns the field's previous
value, which \idle will jump to.

\tryrunlocalspark is shown in algorithm \ref{alg:try_run_local_spark};
It attempts to pop a spark of the engine's deque.
If the spark deque is empty then \tryrunlocalspark
will return NULL.
If it successfully popped a spark it will
check that the engine's current context is compatible with the spark.
If incompatible \tryrunlocalspark will put the spark back on the engines
spark deque return NULL.
However when \idle calls \tryrunlocalspark the spark will always be
compatible;
we will return to this point later.
We then prepare the engine for to execute the spark using
\prepareengineforspark
(algorithm \ref{alg:prepare_engine_for_spark}),
all this entails is making sure that the engine has a context, the context
is loaded and has the correct parent stack pointer in its parent stack
pointer register.
After this \tryrunlocalspark returns the spark's entry point to \idle which
will jump to the code address.

\begin{algorithm}[tbp]
\begin{minipage}{\textwidth}
\begin{verbatim}
struct MR_engine_sleep_sync {
    sem_t                               sleep_sem;
    lock                                lock;
    volatile unsigned                   state;
    volatile unsigned                   action;
    union MR_engine_wake_action_data    action_data;
};

union MR_engine_wake_action_data {
    MR_EngineId     worksteal_engine;
    MR_Context      *context;
};
\end{verbatim}

\begin{algorithmic}
    \Procedure{MR\_sleep}{}
        \Loop
            \State $eng\_data \gets MR\_engine\_sleep\_data$[$engine\_id$]
            \State $eng\_data.state \gets$ SLEEPING
            \State $sem\_wait(eng\_data.sleep_sem)$
            \Switch{$eng\_data.action$}
              \Case{ACTION\_SHUTDOWN}
                \State $\cdots$
              \EndCase
              \Case{ACTION\_RUN\_CONTEXT}
                \State $ctxt \gets eng\_data.action\_data.context$
                \State MR\_load\_context($ctxt$)
                \Goto $ctxt.resume\_label$
              \EndCase
              \Case{ACTION\_STEAL\_SPARK}
                \State $MR\_engine.victim\_counter \gets
                    eng\_data.action\_data.worksteal\_engine$
                \State $code\_ptr \gets$ MR\_try\_steal\_spark()
                \If{$code\_ptr \neq$ NULL}
                    \Goto $code\_ptr$
                \EndIf
                \State $code\_ptr \gets$ MR\_try\_run\_context()
                \If{$code\_ptr \neq$ NULL}
                    \Goto $code\_ptr$
                \EndIf
                \State \Break
              \EndCase
              \Case{ACTION\_NOT\_SPECIFIED}
                \State $code\_ptr \gets$ MR\_try\_run\_context()
                \If{$code\_ptr \neq$ NULL}
                    \Goto $code\_ptr$
                \EndIf
                \State $code\_ptr \gets$ MR\_try\_steal\_spark()
                \If{$code\_ptr \neq$ NULL}
                    \Goto $code\_ptr$
                \EndIf
                \State \Break
              \EndCase
            \EndSwitch
        \EndLoop
    \EndProcedure
\end{algorithmic}

\end{minipage}
\caption{The \sleep code}
\end{algorithm}

\sleep is another hand written Mercury procedure.
It uses an
\enginesleepsync structure to manage the state of each engine.
These structures are organised into a global array indexed by engine ids,
making them accessible to other engines.
each structure contains a semaphore and a lock.
The engine owning the structure waits on \code{sleep\_sem} in order to
sleep,
and \code{lock} is used by other engines to ensure mutual exclusion for
their accesses to the \enginesleepsync structure.
There are three other fields in each structure:
\code{state} is used by the engine that owns the structure to communicate
its state to other engines,
while \code{action} and \code{action\_data} are used by other threads when
communicating to this engine.

Upon jumping into \idle,
an engine sets its state to \code{SLEEPING} and waits on \code{sleep\_sem}.
If another engine posts to \code{sleep\_sem} then the engine is woken up,
and retrieves the value of the \code{action} field.
The engine switches on this value to determine what to do,
such as:
shut down, 
execute a context, or
steal and execute a spark.
If it is instructed to run a context,
it will be passed the context directly
using the \code{action\_data} field.
Similarly, if it instructed to steal a spark,
then \code{action\_data} will tell
it whose spark stack it should begin its round robin search from.
If thread stealing fails,
the engine will check the global context queue for
a runnable context;
if that fails,
then \idle will loop and put the engine back to sleep.
If no action is specified
(the value of the \code{action} field is \code{ACTION\_NOT\_SPECIFIED}),
then \sleep will try to run a context from the global context queue before
attempting to steal a spark.

\begin{algorithm}[tbp]
\begin{algorithmic}
\Procedure{MR\_wake\_engine}{$engine\_id, action, action\_data, states$}
    \State MR\_acquire\_lock($MR\_engine\_sleep\_data$[$engine\_id$]$.lock$)
    \If{$eng\_data.state \in states$}
        \State $MR\_engine\_sleep\_data$[$engine\_id$]$.action \gets action$
        \State $MR\_engine\_sleep\_data$[$engine\_id$]$.action\_data \gets action\_data$
        \State $MR\_engine\_sleep\_data$[$engine\_id$]$.state \gets$ WOKEN
        \State MR\_sem\_post($MR\_engine\_sleep\_data$[$engine\_id$]$.sleep\_sem$)
        \State $result \gets$ true
    \Else
        \State $result \gets$ false
    \EndIf
    \State MR\_release\_lock($MR\_engine\_sleep\_data$[$engine\_id$]$.lock$)
    \State \Return $result$
\EndProcedure
\end{algorithmic}
\caption{\wakeengine}
\label{alg:wake_engine}
\end{algorithm}

Engines may be woken with a call to \wakeengine,
whose code is shown in algorithm \ref{alg:wake_engine}.
\wakeengine takes as parameters the id of the engine to awaken,
the action and its data that the engine should perform upon awakening,
and the set of states from which we may awaken the engine from (usually
\code{SLEEPING}).
The implementation of \wakeengine is mostly straightforward,
one important detail is that we must only wake the engine if it has not
been woken already, this is done by checking the value of
\code{eng\_data.state} after acquiring the lock,
and setting the new state while holding the lock.
The action and action data must also be written to the
\enginesleepsync structure before posting to the target engine's sleep
semaphore.
The parameter \code{states} is a bit field, with each state represented by
its own bit.
This is flexible, it allows us to message an engine regardless of its
current state.
For example,
we shut down an engine by calling \wakeengine with the shut down action and
all bits set in the \code{states} bit field.
Compared to the previous system which used a lock and a condition variable,
this system allows us to wake engines selectively.
This is useful in the case when a context must be executed on a particular
engine because that engine's C stack contains a frame that made a call to
some Mercury code and now must be returned into.
In the future, this feature could be used to schedule computations on
\emph{nearby} processors,
processors that may share a second or third level cache with the current
processor.

\begin{algorithm}[tbp]
\begin{algorithmic}[1]
\Procedure{MR\_join\_and\_continue}{$ST, ContLabel$}
  \State $finished \gets$ MR\_atomic\_dec\_and\_is\_zero($ST.num\_outstanding$)
  \If{$finished$}
    \If{$ST.orig\_context \neq current\_context$}
      \While{$ST.orig\_context.resume\_label \neq ContLabel$}
        \State CPU\_relax
      \EndWhile
      \State MR\_release\_context($current\_context$)
      \State $current\_context \gets$ NULL
      \State MR\_load\_context($ST.parent$)
    \EndIf
    \Goto{$ContLabel$}
  \Else
    \If{$ST.orig\_context = current\_context$}
      \State $MR\_r1 \gets ContLabel$
      \Goto{MR\_idle\_orig\_context}
    \Else
      \Goto{MR\_idle}
    \EndIf
  \EndIf
\EndProcedure
\end{algorithmic}
\caption{\joinandcontinue}
\label{alg:join_and_continue_ws2}
\end{algorithm}

Moving spark deques from contexts to engines made it necessary to change
\idle.
Similarly we must also change the \joinandcontinue barrier.
The new version of \joinandcontinue is shown in algorithm
\ref{alg:join_and_continue_ws2}.
The most significant change is on line 15,
\joinandcontinue no longer attempts to run a spark from the local deque,
it relies on \idle to do this.
The second change is that \joinandcontinue no longer suspends the original
context, it executes \idle while holding the original context.
This would invalidate \idle's precondition that if an engine has a context,
that that context is otherwise free to execute \emph{any} spark,
but an original context may only execute sparks that were created by the
parallel conjunction that it is currently executing.
The new \idle code allows us to create any number of entry points,
we have created the \idleorigcontext entry point which expects to be called
with such a context.
However, since we do not set the context's \code{resume\_label} field until
the engine has given up the context,
we must pass the value of the continuation label to \idleorigcontext.
We do this by using \code{MR\_r1}, the first Mercury abstract machine
register;
this is the normal calling convention for Mercury procedures.

The other change is an optimisation on line 10.
In the old version of this algorithm the engine would schedule the original
context,
by placing it on the run queue,
and then call \idle,
which would most likely take the same context off the run queue and then
execute it.
We are able to take advantage of the knowledge that the original context is
now runnable and the engine's current context is finished,
Therefore, we can release the engine's current context and load the original
context without calling \idle or using the run queue.
This is more efficient as it uses the runqueue less and,
in turn uses the run queue's lock less.

\begin{algorithm}[tbp]
\begin{algorithmic}
    \Procedure{MR\_idle\_orig\_context}{}
        \State $join\_label \gets MR\_r1$
        \State $code\_ptr \gets$ MR\_try\_run\_local\_spark($join\_label$)
        \If{$code\_ptr \neq$ NULL}
            \Goto $code\_ptr$
        \EndIf
        \State MR\_save\_context($ctxt$);
        \State $current\_context.resume\_label \gets join\_label$
        \State $current\_context \gets$ NULL
        \Goto MR\_idle
    \EndProcedure
\end{algorithmic}
\caption{New entry point to the idle loop for dirty contexts.}
\label{alg:idle_orig_context}
\end{algorithm}

The new entry point \idleorigcontext is shown in algorithm
\ref{alg:idle_orig_context}.
This entry point expects to be called from \joinandcontinue while the engine
is holding a context that is needed to complete a parallel conjunction.
Using \tryrunlocalspark (algorithm \ref{alg:try_run_local_spark},
it tries to run a spark from the engine's local spark deque first.
When we introduced \tryrunlocalspark above,
we said that it checked whether the spark at the top of the spark deque was
compatible with the current context;
when \tryrunlocalspark is called from \idleorigcontext this test can fail
because the spark may be related to a different parallel conjunction than
the one that the engine's current context has been executing.
When this happens \tryrunlocalspark will put the spark back onto the spark
deque and return \NULL.
Below we describe why it is best to put the spark back on the deque.
It will also return \NULL when there is no spark on the deque.
If non-\NULL was returned then \idleorigcontext will jump to the code
address that \tryrunlocalspark returned,
otherwise it will save its current context,
set the context's \code{resume\_label} field
and jump to \idle which attempts to find work as described above,
which involves looking for work with \tryruncontext, \tryrunlocalspark, and
\trystealspark.
If the earlier call to \tryrunlocalspark put an incompatible spark back onto
the spark deque,
and the call to \tryruncontext did not find a runnable context then
the next call to \tryrunlocalspark
will retrieve the spark from the top of the deque and be able to execute it,
provided that the spark was not stolen in the meantime.
The spark will now be compatible because the engine released its context
before jumping to \idle.
This is one of two simple ways to handle context-spark incompatibility:
the other is to suspend the current context at the moment when we find that
a spark is incompatible.
Both solutions require a context switch,
but the solution that we have chosen will also attempt to execute a
suspended context before attempting to execute the spark using a new context
(we described above that it is best to execute a suspended context rather
than a spark).

We could add further entry points in the future if we found them useful,
and they do not have to jump to \idle when they finish.
For example,
it may be useful to create a special case for when an engine is known to
have a empty context;
this case could check for work in a different order and and if it does not
find any work it could jump to \sleep the way \idle currently does.

\input{tab_work_stealing_revised}

\plan{Benchmark}
Table \ref{tab:work_stealing_revised} shows a comparison of the previous
work stealing implementation with this one.
There are four row groups with two rows each.
Each row group gives the results for a single program,
while the rows in each group give the results for the previous work stealing
system and the current one.
The right recursive mandelbrot program was compiled with the conjunct
reordering transformation from section \ref{sec:rts_reorder} disabled,
otherwise it would have had the same results as the left recursive version
of the same program.
It is still important to test right recursion,
such as in this example as the conjunct reordering transformation cannot
reorder dependent parallel conjunctions.

Programmers are encouraged to avoid embarrassing parallelism,
so that the overheads of parallelisation have a small enough effect on the
program's performance while still exposing enough parallelism to the
language and runtime system so that the program can run efficiently.
The mandelbrot program is written with this in mind:
the loop over the rows of the image is parallelised,
but the inner loop over the pixels in each row is not.
This makes it difficult to benchmark changes to the runtime system such as
the changes to the work stealing implementation above.

\begin{figure}
\begin{verbatim}
:- func fibs(int, int) = int.

fibs(N, Depth) = F :-
    ( N < 2 ->
        F = 1
    ;
        ( Depth > 0 ->
            (
                F1 = fibs(N-1, Depth-1)
            &
                F2 = fibs(N-2, Depth-1)
            )
        ;
            F1 = fibs_seq(N-1),
            F2 = fibs_seq(N-2)
        ),
        F = F1 + F2
    ).
\end{verbatim}
\caption{\fibs with granularity control}
\label{fig:fibs}
\end{figure}

In order to benchmark these changes easily,
we added a micro-benchmark named fibs which calculates the 43rd Fibonacci
number.
Fibs uses a naive algorithm which is a direct translation of the recursive
definition of the $N$th Fibonacci number.
The parallel \fibs\footnote{
    The arity of a Mercury function is written as \code{N+1}.
    The \code{+1} refers the return value while \code{N} refers to the
    function's input arguments.}
function is shown in figure \ref{fig:fibs}.
The recursive definition of fibs has two independent recursive calls in
the same branch;
they are parallelised against one another.
Parallelism is introduced in this way at each level of the recursion
creating many very small parallel tasks,
since the remainder of the computation consists of comparsion and addition.
When an algorithm such as this is parallelised it creates embarrassing
parallelism.
This behaviour makes it easy for us to measure the effects of things such as
work stealing.

The easiest way to avoid this is to introduce \emph{granularity control}.
We have added granularity control by adding a new parameter to \fibs called
\code{Depth}.
We use \code{Depth} to control the sizes and number of parallel tasks
created by \fibs.
At each recursive call \code{Depth} is decremented;
if it becomes zero, then the implementation will call a sequential
version of the \fibs function.

Table \ref{tab:work_stealing_revised} shows results for fibs with several
different initial values for \code{Depth}.
Fibs has better parallel performance when \code{Deoth}'s initial value is
smaller,
demonstrating how granularity control effects performance.
\paul{XXX: Re-do benchmarks so I can explain them.}

We have shown results where the initial value for Depth is 30,
meaning that the top 30 levels of the call graph are executed in parallel
and any work beneath that is executed sequentially.
This is just one type of granularity control.
Granularity control is any method used to avoid
embarrassing parallelism by turning a computation with 
many small parallel tasks into one with fewer larger parallel tasks.

% XXX
However,
we are using unusually high values of \code{Depth} (such as 30) to allow us
to compare the two work stealing implementations.

since we are including fibs because it is a micro benchmark then
observing how these overheads affect its performance is desirable,
which is why we use a high initial value for \code{Depth} such as 30,
and why we've shown a version without granularity control at all.




\plan{Evaluation}

\plan{Further potential work}
\plan{Steal half}
We have noticed that in many workloads such as a left recursive parallel
loop one engine creates all the sparks.
In a situation like this,
work stealing becomes more common than local work execution.
One processor would execute work locally while $P - 1$ processors act as
thieves,
and the original engine's work queue can become a bottleneck.
To avoid this behaviour,
a thief could steal more than one spark from a victim and put all but one of
those sparks on its own deque.
Each time this happens work becomes distributed among more of the engines,
which improves the probability that a given victim has work on its deque.
The numbers of sparks on each engine's deque should stabilise,
and then work stealing will become less frequent as each engine will prefer to
take work from the hot end of its own deque.
Executing more work from one's own deque, and decreasing the amount of stealing
should both improve the efficiency of the program as a whole.

We are currently using the the deque data structure and algorithms described by
\citet{Chase_2005_wsdeque} (CL Deque).
\citet{hendler:2002:stealhalf} (HS Deque) describes a similar data structure
and set of algorithms that allow half the work to be stolen in a single lock
free operation.
These data structures are similar:
they are both based on \citet{arora:1998:work-stealing}.
The HS Deque differs from 
\citet{arora:1998:work-stealing}
by stealing half the work from a victim's deque,
whilst the CL Deque differs by structuring each deque as
dynamically resizable circular buffer.
We have chosen to use the CL Deque because it is resizable,
a feature that we identified as important (section \ref{sec:rts_work_stealing}).
Furthermore,
if we ever adopt a steal half deque (or any work stealing deque that allows
us to steal more than one item in a single operation) we will have to
consider spark execution order carefully.
Therefore,
these ideas may be interesting for further work.

\plan{memory hierarchy awareness}
Another potential improvement is in the selection of a thief's victim.
A thief may wish to prefer victims that are nearby in terms of memory
topology, so that communication of the data relevant to the spark is
cheaper.
This can also be used when selecting which engine to wake up in order to
pass work to it.
We discuss memory hierarchy awareness in more detail in the next section.

