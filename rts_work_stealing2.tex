
\status{Not written}

In this section we take the opportunity to improve on our work stealing
implementation from Section \ref{sec:rts_work_stealing}.
While we made these improvments we also found it useful to change how idle
engines behave.
Although these too changes are conceptually distinct,
they where made together and their implementations are interlinked.
Therefore we will present and benchmark them together as one set of changes.

\plan{Describe problems with associating stacks with contexts}
Sparks are stored on context local deques,
this has a several significant problems.

\begin{description}

    \item[There is a dynanic number of spark deques]~

    The number of contexts changes during a programs execution,
    therefore the number of spark deques also changes.
    This means that we must have code to manage this chaging number of
    deques.
    This code makes the runtime system more complicated necessary,
    both when stealing a spark and when destroying or creating a context.

    \item[This requires locking]~

    The management of contexts must be thread safe so that the set of
    spark deques is not currupted.
    We store spark deques in a global array protected by a lock.
    It may be possible to replace the array with a lock free datastructure.
    However it is better to remove the need of thread safty by using a
    constant set of deques.

    \item[A large number of contexts makes work stealing slower]~
    
    In previous sections
    we have shown that the number of contexts in use can often be very high,
    much higher than the number of Mercury engines.
    If there are $N$ engines and $M$ contexts,
    then there can be at most $N$ contexts running and
    at least $M-N$ contexts suspended (blocked and waiting to run),
    In some cases there can be at most $M-1$ suspended contexts.
    A context can become suspended in one of two ways:
    by blocking on a future's value in call to \wait,
    or by blocking on an incomplete conjunct in a call to \joinandcontinue.
    We attempt to minimise the former case and the later case cannot occur
    if the context has a spark on its local spark deque (it would run the
    spark rather than block).
    Therefore the large majority of the suspended contexts will not have
    sparks on their deques,
    and the probability of selecting a deque at random with a spark on its
    stack is only a little bit higher than $M \choose N$ at best and
    and $M \choose 1$ at worst.
    Furthermore the value of $M$ can be very high in pathological cases.
    If an engine does not successfully steal a spark from a deque,
    it will continue by trying to steal a spark from a different deque.
    An engine can exhaust all its attempts, even when there is work
    available.
    Upon exhausting all its attempts or all the deques,
    the engine will sleep before making another round of attempts.
    Each round of attempts (regardless of success or failure) has a
    complexity of $O(M)$.

\end{description}

\noindent
\plan{We associate stacks with engines}
The solution to all of these problems is to associate spark deques with
engines rather than with contexts.
A running Mercury program has a constant number of engines,
and therefore the number of spark deques will not vary.
This has allowed us to remove the code used to resize the deque array,
the array is filled in when the engines are created during startup,
after which it is never modified.
This code is much simpler as it never needs to resize the array.
Context creation and distruction is now simpler and faster,
it does not need to use the spark array at all, and certainly never contends
for the spark array lock.
We can also remove the locking code in \trystealspark used to ensure that
the array is not changed while a thief is trying to steal a spark.
The cost of work stealing also becomes linear in the number of engines
rather than the number of contexts (there are usually fewer engines than
contexts).

\begin{algorithm}
\begin{algorithmic}[1]
\Procedure{MR\_try\_steal\_spark}{$spark\_ptr$}
  \State $result \gets false$
  \For{$attempt = 0$ to $MR\_num\_engines$}
    \State $victim\_index \gets
        (MR\_engine.victim\_counter + attempt) \bmod MR\_num\_engines$
    \State $deque \gets
       MR\_spark\_deques$[$victim\_index$]
    \State $result \gets$ steal\_spark($deque$, $spark\_ptr$)
    \If{$result$}
      \State break
    \EndIf
  \EndFor
  \State $MR\_engine.victim\_counter \gets
    MR\_engine.victim\_counter + offset$
  \State \Return $result$
\EndProcedure
\end{algorithmic}
\caption{MR\_try\_steal\_spark}
\label{alg:try_steal_spark_revised}
\end{algorithm}

\plan{Show new \trystealspark}
We have made some other changes to \trystealspark,
its new code is shown in Algorithm \ref{alg:try_steal_spark_revised}.
The lock was also used to protect the victim counter,
ensuring that round robbin selection of the victim was maintained.
Now each engine independently performs its own round robin selection of the
victim using a new field \code{victim\_counter} in the engine structure.
We have not evaluated if this policy works better or worse,
even if it is worse,
it avoids the cost of a lock which is more significant.
The two other changes are minor,
we have removed the configurable limit of the number of work stealing
attempts per round,
and the test for null array slots has been removed as it is now unnecessary.

\plan{Show how this is safe.}
Associating the spark deques with engines can change the order in which
sparks are executed,
we have to ensure that the system is still deadlock free.
In the previous version
a context that is suspended by a call to \wait may contain sparks,
while the context is suspended those sparks can only be accessed by a theif,
even if the theif is the same engine that created the sparks.
In the current version,
those sparks are now associated with the engine,
once the context is suspended the engine can access those sparks from its
own spark deque.
If the engine attempts to execute one of these sparks it will need a
context.
At this point we have two choices,
the engine must either execute an existing suspended context,
or allocate a new context for a spark on its spark deque \emph{dispite} the
context limit.
There may not always be a suspended context but if there is it should
eventually be executed to avoid a deadlock
(it may unblock a future that another context is blocked on).
It may also be optimal to execute a suspended context,
since it may prevent the context limit from being exeeded.
But more importantly,
if the engine executed a spark,
and created a new context for the spark,
then that context might also block on a future,
this situation could loop, allocating more contexts dispite the context
limit.
Therefore this would not create a deadlock provided that an engine without a
context attempts to resume a suspended context before attempting to execute
one of its own sparks.

We have modified \getglobalwork to implement this,
now \getglobalwork attempts to run a suspended context,
then attempts to run a local spark and finally attempts to steal a spark
before going to sleep.
We took this opportunity to significantly change \getglobalwork,
we introduced a number of optimisations and fixed another problem.
When an engine fails to find any work and goes to sleep a timout is used to
wake it up.
This timeout defaults to 2ms.
When a context created a spark,
the idle engine would take an average of 1ms before attempting to steal the
spark.
If the context finished the first conjunct of a parallel conjunction it
would often take the task back off its deque before the thief stole it.
This results in sequential execution even though an idle engine was
available to run the spark.
Secondly,
using the timeout when there is no parallel work available is wasteful
as idle engines would wake up and needlessly attempt to steal work.
Therefore while modifying \getglobalwork we chose to remove the timeout,
we should instead notify sleeping engines of sparks, but this notification
should have a low cost.

%\begin{multicols}{2}

\begin{algorithm}

\begin{minipage}{\textwidth}
\begin{multicols}{2}
\begin{verbatim}
#define TRAMPOLINE(call)        \\
    do {                        \\
        MR_Code *code;          \\
        code = (call);          \\
        if (code) {             \\
            goto code;          \\
        }                       \\
    } while(0)
\end{verbatim}

\begin{algorithmic}
    \Procedure{MR\_idle}{}
        \State \tramp{try\_run\_context()}
        \State \tramp{try\_run\_local\_spark($NULL$)}
        \State \tramp{try\_steal\_spark($NULL$)}
        \Goto MR\_sleep
    \EndProcedure
\end{algorithmic}

\begin{algorithmic}
    \Procedure{MR\_idle\_dirty\_context}{}
        \State $join\_label \gets MR\_r1$
        \State \tramp{try\_run\_local\_spark($join\_label$)}
        \State \tramp{try\_steal\_spark($join\_label$)}
        \State save\_dirty\_context($join\_label$)
        \State \tramp{try\_run\_context()}
        \Goto MR\_sleep
    \EndProcedure
\end{algorithmic}

\end{multicols}

\begin{verbatim}
struct engine_sleep_sync_i {
    sem_t                               sleep_sem;
    sem_t                               wake_sem;
    volatile unsigned                   state;
    volatile unsigned                   action;
    union MR_engine_wake_action_data    action_data;
};

union MR_engine_wake_action_data {      
    MR_EngineId     worksteal_engine;
    MR_Context      *context;
};
\end{verbatim}

\begin{algorithmic}
    \Procedure{MR\_sleep}{}
        \Loop
            \State $eng\_data \gets MR\_engien\_sleep\_data$[$engine\_id$]
            \State $eng\_data.state \gets$ SLEEPING
            \State $sem\_wait(eng\_data.sleep_sem)$
            \Switch{$eng\_data.action$}
              \Case{ACTION\_SHUTDOWN}
                \State $\cdots$
              \EndCase
              \Case{ACTION\_RUN\_CONTEXT}
                \State $ctxt \gets eng\_data.action\_data.context$
                \State MR\_load\_context($ctxt$)
                \Goto $ctxt.resume\_label$
              \EndCase
              \Case{ACTION\_STEAL\_SPARK}
                \State $MR\_engine.victim\_counter \gets
                    eng\_data.action\_data.worksteal\_engine$ 
                \State \tramp{try\_steal\_spark(NULL)}
                \State \tramp{try\_run\_context}
                \State break
              \EndCase
              \Case{ACTION\_NONE}
                \State \tramp{try\_run\_context}
                \State \tramp{try\_steal\_spark(NULL)}
                \State break
              \EndCase
            \EndSwitch
        \EndLoop
    \EndProcedure
\end{algorithmic}

\end{minipage}
\caption{New \getglobalwork ~/ \idle code}
\end{algorithm}

\paul{Consider removing MR\_ from most if not all symbols.}

%\end{multicols}

\plan{Solution, wake engines for different types of work}
We modified the RTS so that waking an engine is easy, and it can be given a
message so that it knows where to look for work.

\plan{A lot of work went into preventing deadlocks due to race conditions,
a thread that is not yet sleeping if notified must wake up immediately.}

\plan{Show new \getglobalwork}
\plan{Show the algorithm for the new idle loop.}
Note that we execute contexts before sparks,
this is more-likely to produce futures and it may reduce memory consumption.

\plan{Extra benefit: when an engine is woken it can be told directly where
to find work, or be given the work directly.}

\plan{Extra benefit: we can be selective about which engine to wake,
while not implemented fully, we can wake a `nearby' engine so that
we can avoid communication between dies or sockets.}

\input{tab_work_stealing_revised}

\plan{Benchmark}

\plan{Evaluation}

\plan{Further potential work}

