
\status{Not written}

In this section we take the opportunity to improve on our work stealing
implementation from Section \ref{sec:rts_work_stealing}.
While we made these improvements we also found it useful to change how idle
engines behave.
Although these too changes are conceptually distinct,
they where made together and their implementations are interlinked.
Therefore we will present and benchmark them together as one set of changes.

\plan{Describe problems with associating stacks with contexts}
Sparks are stored on context local deques,
this has a several significant problems.

\begin{description}

    \item[There is a dynamic number of spark deques]~

    The number of contexts changes during a programs execution,
    therefore the number of spark deques also changes.
    This means that we must have code to manage this changing number of
    deques.
    This code makes the runtime system more complicated necessary,
    both when stealing a spark and when destroying or creating a context.

    \item[This requires locking]~

    The management of contexts must be thread safe so that the set of
    spark deques is not corrupted.
    We store spark deques in a global array protected by a lock.
    It may be possible to replace the array with a lock free data structure.
    However it is better to remove the need of thread safety by using a
    constant set of deques.

    \item[A large number of contexts makes work stealing slower]~
    
    In prior sections
    we have shown that the number of contexts in use can often be very high,
    much higher than the number of Mercury engines.
    If there are $N$ engines and $M$ contexts,
    then there can be at most $N$ contexts running and
    at least $M-N$ contexts suspended (blocked and waiting to run),
    In some cases there can be at most $M-1$ suspended contexts.
    A context can become suspended in one of two ways:
    by blocking on a future's value in call to \wait,
    or by blocking on an incomplete conjunct in a call to \joinandcontinue.
    We attempt to minimise the former case and the later case cannot occur
    if the context has a spark on its local spark deque (it would run the
    spark rather than block).
    Therefore the large majority of the suspended contexts will not have
    sparks on their deques,
    and the probability of selecting a deque at random with a spark on its
    stack is only a little bit higher than $M \choose N$ at best and
    and $M \choose 1$ at worst.
    Furthermore the value of $M$ can be very high in pathological cases.
    If an engine does not successfully steal a spark from a deque,
    it will continue by trying to steal a spark from a different deque.
    An engine can exhaust all its attempts, even when there is work
    available.
    Upon exhausting all its attempts or all the deques,
    the engine will sleep before making another round of attempts.
    Each round of attempts (regardless of success or failure) has a
    complexity of $O(M)$.

\end{description}

\noindent
\plan{We associate stacks with engines}
The solution to all of these problems is to associate spark deques with
engines rather than with contexts.
A running Mercury program has a constant number of engines,
and therefore the number of spark deques will not vary.
This has allowed us to remove the code used to resize the deque array,
the array is filled in when the engines are created during startup,
after which it is never modified.
This code is much simpler as it never needs to resize the array.
Context creation and destruction is now simpler and faster,
it does not need to use the spark array at all, and certainly never contends
for the spark array lock.
We can also remove the locking code in \trystealspark used to ensure that
the array is not changed while a thief is trying to steal a spark.
The cost of work stealing also becomes linear in the number of engines
rather than the number of contexts (there are usually fewer engines than
contexts).

\begin{algorithm}[tbp]
\begin{algorithmic}[1]
\Procedure{try\_steal\_spark}{$spark\_ptr$}
  \State $result \gets false$
  \For{$attempt = 0$ to $MR\_num\_engines$}
    \State $victim\_index \gets
        (MR\_engine.victim\_counter + attempt) \bmod MR\_num\_engines$
    \State $deque \gets
       MR\_spark\_deques$[$victim\_index$]
    \State $result \gets$ steal\_spark($deque$, $spark\_ptr$)
    \If{$result$}
      \State break
    \EndIf
  \EndFor
  \State $MR\_engine.victim\_counter \gets
    MR\_engine.victim\_counter + offset$
  \State \Return $result$
\EndProcedure
\end{algorithmic}
\caption{try\_steal\_spark}
\label{alg:try_steal_spark_revised}
\end{algorithm}

\plan{Show new \trystealspark}
We have made some other changes to \trystealspark,
its new code is shown in Algorithm \ref{alg:try_steal_spark_revised}.
The lock was also used to protect the victim counter,
ensuring that round robin selection of the victim was maintained.
Now each engine independently performs its own round robin selection of the
victim using a new field \code{victim\_counter} in the engine structure.
We have not evaluated if this policy works better or worse,
even if it is worse,
it avoids the cost of a lock which is more significant.
The two other changes are minor,
we have removed the configurable limit of the number of work stealing
attempts per round,
and the test for null array slots has been removed as it is now unnecessary.

\plan{Show how this is safe.}
Associating the spark deques with engines can change the order in which
sparks are executed,
we have to ensure that the system is still deadlock free.
In the previous version
a context that is blocked on a call to \wait may contain sparks
which can only be accessed by a thief,
In the current version,
those sparks are now associated with the engine that the context was running
on,
and therefore that engine has the opportunity to run those sparks by
retrieving them from the hot end of its own deque.
If the engine attempts to execute one of these sparks it will need a
context,
and the creation of a new context may exceed the context limit even though
the spark is being executed locally.
This is just one instance where an engine \emph{without a context}
may try to run a spark from its own deque,
in the previous version a context would always be available because sparks
where associated with contexts.

\begin{algorithm}[tbp]
\begin{multicols}{2}

\parbox{\textwidth}{
\begin{algorithmic}
    \Procedure{MR\_idle}{}
        \State \tramp{try\_run\_context()}
        \State \tramp{try\_run\_local\_spark($NULL$)}
        \State \tramp{try\_steal\_spark()}
        \Goto MR\_sleep
    \EndProcedure
\end{algorithmic}
}

\begin{minipage}{\textwidth}
\begin{verbatim}
#define TRAMPOLINE(call)        \\
    do {                        \\
        MR_Code *code;          \\
        code = (call);          \\
        if (code) {             \\
            goto code;          \\
        }                       \\
    } while(0)
\end{verbatim}
\end{minipage}

\end{multicols}
\caption{New \idle code}
\label{alg:idle_entry_point}
\end{algorithm}

\paul{Rename \getglobalwork throughout previous sections to \idle}.

An idle engine without a context calls \idle to acquire new work,
\idle's code is shown in Algorithm \ref{alg:idle_entry_point}.
\idle has changed significantly,
many of its details shown in previous sections have been moved into C
functions,
these include:
\tryruncontext which tries to execute a suspended but runnable context;
\tryrunlocalspark which tries to run a spark from the top of the engine's
spark deque, possibly creating a new context for the spark;
and 
\trystealspark which was shown above in Algorithm
\ref{alg:try_steal_spark_revised}.
Because running a local spark may allocate a context and exceed the context
limit,
the engine must execute any suspended but runnable context instead.
Doing so is always permitted despite the context limit.
Furthermore,
a context whose execution has already begin may make more parallel work
available creating sparks or signalling futures.
If the engine is able to run the context until the completion of its work
(until the contexts executes the \joinandcontinue barrier at the end of a
parallel conjunct)
then this may make the context available to execute a spark from the
engine's local spark queue.
Therefore we always try to run a context (using \tryruncontext)
before attempting to run a local spark (using \tryrunlocalspark).
Of course there will be cases when \tryruncontext fails and an engine
without a context then attempts to run a local spark.
To facilitate this, the context limit is not checked in \tryrunlocalspark
(it is still used in \trystealspark).

\idle is a hard coded Mercury procedure and it does not return control to
its caller,
therefore it continues execution by jumping to the code address of the next
thing to execute.
This can either be the resume address of a context,
the entry point of a spark,
or the Mercury procedure \sleep.
However
the C functions are used to find the next context or spark to execute,
if successful these C functions prepare the engine to execute the spark or
context and then return the address that the engine should execute.
they \emph{must} return rather than execute the spark or context directly so
that the C stack pointer has the same value that it did upon entering \idle.
\idle uses a \emph{trampoline}\footnote{
    Trampoline is an overloaded term in computer science.
    The reader may or may not agree with our use of this term.
    }
macro to jump to the returned code
address or fall through to the next instruction if the function returned
false.
If the idle engine cannot find a spark or context to execute then it jumps
to \sleep.

\begin{algorithm}[tbp]
\begin{minipage}{\textwidth}
\begin{verbatim}
struct engine_sleep_sync {
    sem_t                               sleep_sem;
    lock                                lock;
    volatile unsigned                   state;
    volatile unsigned                   action;
    union MR_engine_wake_action_data    action_data;
};

union MR_engine_wake_action_data {      
    MR_EngineId     worksteal_engine;
    MR_Context      *context;
};
\end{verbatim}

\begin{algorithmic}
    \Procedure{MR\_sleep}{}
        \Loop
            \State $eng\_data \gets MR\_engine\_sleep\_data$[$engine\_id$]
            \State $eng\_data.state \gets$ SLEEPING
            \State $sem\_wait(eng\_data.sleep_sem)$
            \Switch{$eng\_data.action$}
              \Case{ACTION\_SHUTDOWN}
                \State $\cdots$
              \EndCase
              \Case{ACTION\_RUN\_CONTEXT}
                \State $ctxt \gets eng\_data.action\_data.context$
                \State MR\_load\_context($ctxt$)
                \Goto $ctxt.resume\_label$
              \EndCase
              \Case{ACTION\_STEAL\_SPARK}
                \State $MR\_engine.victim\_counter \gets
                    eng\_data.action\_data.worksteal\_engine$ 
                \State \tramp{try\_steal\_spark()}
                \State \tramp{try\_run\_context()}
                \State break
              \EndCase
              \Case{ACTION\_NONE}
                \State \tramp{try\_run\_context()}
                \State \tramp{try\_steal\_spark()}
                \State break
              \EndCase
            \EndSwitch
        \EndLoop
    \EndProcedure
\end{algorithmic}

\end{minipage}
\caption{The \sleep code}
\end{algorithm}

\sleep is another hand written Mercury procedure.
It uses an
\enginesleepsync structure to manage the state of each engine.
These structures are organised into a global array indexed by engine ids,
making them accessible to other engines.
The structure contains a semaphore and a lock;
the engine owning the structure waits on \code{sleep\_sem} in order to
sleep,
and \code{lock} is used by other engines to control their mutual
access to the \enginesleepsync structure.
There are three other fields in the structure:
\code{state} is used by the engine that owns the structure to communicate
its state to other engines,
\code{action} and \code{action\_data} are used by other threads when
communicating to this engine.

Upon jumping into \idle an engine sets its state to \code{SLEEPING} and
waits on \code{sleep\_sem}.
If another engine posts to \code{sleep\_sem} then the engine is woken up,
and retrieves the value of the \code{action} field.
This field can be used to tell the engine what to do upon wakening.
It may be instructed to shutdown, to execute a context or to steal a spark.
If it is instructed to run a context it can be passed the context directly
using the \code{action\_data} field,
similarly, if it instructed to steal a spark \code{action\_data} will tell
it whose spark stack it should begin its round robin search from.
If thread stealing fails the engine will check the global contest queue for
a runnable context,
if that fails then \idle will loop and putting the engine back to sleep.
If no action is specified
(the value of the \code{action} field is \code{ACTION\_NONE})
them \sleep will try to run a context from the global context queue before
attempting to steal a spark.

\begin{algorithm}[tbp]
\begin{algorithmic}
\Procedure{wake\_engine}{$engine\_id, action, action\_data, states$}
    \State $eng\_data \gets MR\_engine\_sleep\_data$[$engine\_id$]
    \State acquire\_lock($eng\_data.lock$)
    \If{$eng\_data.state \in states$}
        \State $eng\_data.action \gets action$
        \State $eng\_data.action\_data \gets action\_data$
        \State $eng\_data.state \gets$ WOKEN
        \State sem\_post($eng\_data.sleep\_sem$)
        \State $result \gets$ true
    \Else
        \State $result \gets$ false
    \EndIf
    \State release\_lock($eng\_data.lock$)
    \Return $result$
\EndProcedure
\end{algorithmic}
\caption{\wakeengine}
\label{alg:wake_engine}
\end{algorithm}

Engines may be woken with a call to \wakeengine whose code is shown in
Algorithm \ref{alg:wake_engine}.
\wakeengine takes id of the engine to awaken,
the action and its data that the engine should perform upon awakening,
and the set of states that we may awaken the engine from (usually
\code{SLEEPING}).
The implementation of \wakeengine is mostly straightforward,
the important details are that we must only wake the engine if it has not
been woken already, this is done by checking the value of
\code{eng\_data.state} after acquiring the lock,
and setting the new state while holding the lock.
The action and action data must also be written to the
\enginesleepsync structure before posting to the engine's sleep
semaphore.
The parameter \code{states} is a bit field, with each state represented by
its own bit.
This is flexible, it allows us to message an engine regardless of its
current state.
For example,
we shutdown an engine by calling \wakeengine with the shutdown action a and
all bits set in the \code{states} bit field.
Compared to the previous system where a lock and condition variable were
used,
this system allows us to wake engines selectively.
This is useful in the case when a context must be executed on a particular
engine because that engine's C stack contains a frame that made a call to
some Mercury code and now must be returned into.
In the future this feature could be used to schedule computations on
\emph{nearby} processors,
processors that may share a second or third level cache with the current
processor.

\begin{algorithm}[tbp]
\begin{algorithmic}[1]
\Procedure{MR\_join\_and\_continue}{$ST, ContLabel$}
  \State $finished \gets$ atomic\_dec\_and\_is\_zero($ST.num\_outstanding$)
  \If{$finished$}
    \If{$ST.orig\_context = this\_context$}
      \Goto{$ContLabel$}
    \Else
      \While{$ST.orig\_context.resume\_label \neq ContLabel$}
        \State CPU\_relax
      \EndWhile
      \State release\_context($this\_context$)
      \State $this\_context \gets$ NULL
      \State load\_context($ST.parent$)
      \Goto{$ContLabel$}
    \EndIf
  \Else
    \If{$ST.orig\_context = this\_context$}
      \State $MR\_r1 \gets ContLabel$
      \Goto{MR\_idle\_orig\_context}
    \Else
      \Goto{MR\_idle}
    \EndIf
  \EndIf
\EndProcedure
\end{algorithmic}
\caption{\joinandcontinue}
\label{alg:join_and_continue_ws2}
\end{algorithm}

By moving spark deques from contexts to engines we had to change \idle.
We have also had to change the \joinandcontinue barrier.
The new version of \joinandcontinue is shown in Algorithm
\ref{alg:join_and_continue_ws2}.
The most significant change is on line 15,
\joinandcontinue no longer attempts to run a spark from the local deque,
it relies on \idle to do this.
The second change is that \joinandcontinue no longer suspends the original
context, it executes \idle while holding the original context.
This would invalidate \idle's precondition that if an engine has a context,
that that context is otherwise free to execute \emph{any} spark,
but an original context may only execute sparks that were created by the
parallel conjunction that it is currently executing.
The new \idle code allows us to create any number of entry points,
we have created the \idleorigcontext entry point which expects to be called
with such a context.
However, since we do not set the contest's \code{resume\_label} field until
the engine has given up the context,
we must pass the value of the continuation label into \idleorigcontext.
This is done using \code{MR\_r1}, the first Mercury abstract machine
register;
this is the normal calling convention used by compiled Mercury procedures.

The other change is an optimisation on line 10.
if the parallel conjunction has been finished and this engine is not
executing the original context,
then instead of placing the original context on the context run queue as the
previous version did,
the new version unloads its current context and resumes execution of the
original context,
This has three benefits,
firstly, this does not use the run queue's lock,
making it more efficient.
Secondly, in the old algorithm, the engine would schedule the context and
call \idle,
where it would check the context run queue and was likely to run the same
context anyway.
Thirdly, by deliberately running the context on the CPU that most
recently completed the parallel conjunction,
we may be able to take advantage of relevant data being hot in the CPU's
cache.

\begin{algorithm}[tbp]
\begin{algorithmic}
    \Procedure{MR\_idle\_orig\_context}{}
        \State $join\_label \gets MR\_r1$
        \State \tramp{try\_run\_local\_spark($join\_label$)}
        \State suspend($join\_label$);
        \State $this\_context.resume\_label \gets join\_label$
        \State $this\_context \gets$ NULL
        \State \tramp{try\_run\_context()}
        \State \tramp{try\_run\_local\_spark(NULL)}
        \State \tramp{try\_steal\_spark()}
        \Goto MR\_sleep
    \EndProcedure
\end{algorithmic}
\caption{New entry point to the idle loop for dirty contexts.}
\label{alg:idle_orig_context}
\end{algorithm}

The new entry point \idleorigcontext is shown in Algorithm
\ref{alg:idle_orig_context}.
This entry point expects to be called from \joinandcontinue while the engine
is holding a context that is needed to complete a parallel conjunction.
It tries to run a spark from the engine's local spark deque first,
the \tryrunlocalspark will check if the spark at the top of the spark deque
is compatible with the current context,
if it is not it will put the spark back onto the spark deque and return
\NULL, it also returns \NULL if there is no spark on the deque.
\idleorigcontext uses the trampoline macro from Algorithm
\ref{alg:idle_entry_point} to jump to the spark's entry point
\tryrunlocalspark found a valid spark.
Next \idleorigcontext saves the context that the engine was using and then
attempts to resume a suspended context,
failing that it retries running a local spark,
this is done because there may have been a spark on the engine's spark deque
that was not compatible, but now that the engine has no context, any spark
is compatible.
If this also fails then
\idleorigcontext will attempt to steal a spark from another engine and run
it,
failing that the engine will jump to \sleep.
We could add further entry points in the future if we found them useful,
for example,
it may be useful to distinguish between cases where an engine already has a
context or does not have a context.

\paul{XXX: Consider removing MR\_ from most if not all symbols.}

\input{tab_work_stealing_revised}

\plan{Benchmark}
\paul{XXX: There's something wrong with the prior left recursive results,
the thread safe sequential time is slower than it should be thus we get stupidly high speedups}
\paul{Also, when comparing absolute times the new work stealing code is
slower, maybe due to the order we check for work in \idle in?}

\plan{Evaluation}

\plan{Further potential work}
\plan{Steal half}
Our work stealing implementation could be improved and tuned further.
We have noticed that in many workloads such as a left recursive parallel
loop one engine creates all the sparks, all the parallelism comes from one
place.
In a situation like this work stealing becomes more common than local work
execution,
one processor would execute work locally while $P - 1$ processors act as
thieves, and a single work queue can again become a bottleneck.
To avoid this behaviour
a steal-half implementation (such as \citet{hendler:2002:stealhalf})
should quickly distributed work evenly between the processors,
reducing the overall number of work stealing operations.
\plan{memory hierarchy awareness}
Another potential improvement is in the selection of a thief's victim.
A thief may wish to prefer victims that are nearby in terms of memory
topology, so that communication of the data relevant to the spark is
cheaper.
This can also be used when selecting which engine to wake up in order to
pass work to it.
We discuss memory hierarchy awareness in more detail in the next section.

