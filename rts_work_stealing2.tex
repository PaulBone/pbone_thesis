
\status{Currently acting on feedback}

In this section we take the opportunity to improve on our work stealing
implementation from Section \ref{sec:rts_work_stealing}.
While we made these improvements,
we also found it useful to change how idle engines behave.
Although these too changes are conceptually distinct,
they were made together and their implementations are interlinked.
Therefore we will present and benchmark them together as one set of changes.

\plan{Describe problems with associating stacks with contexts}
Sparks were originally stored on context local deques,
which has several significant problems.

\textbf{There is a dynamic number of spark deques.}
The number of contexts changes during a programs execution,
therefore the number of spark deques also changes.
This means that we must have code to manage this changing number of
deques.
This code makes the runtime system more complicated than necessary,
both when stealing a spark and when creating or destroying a context.

\textbf{Locking is required.}
The management of contexts must be thread safe so that the set of
spark deques is not corrupted.
We store spark deques in a global array protected by a lock.
It may be possible to replace the array with a lock free data structure.
However it is better to remove the need for thread safety by using a
constant set of deques.

\textbf{A large number of contexts makes work stealing slower.}
In prior sections
we have shown that the number of contexts in use can often be very high,
much higher than the number of Mercury engines.
If there are $N$ engines and $M$ contexts,
then there can be at most $N$ contexts running and
at least $M-N$ contexts suspended (blocked and waiting to run).
A context can become suspended in one of two ways:
by blocking on a future's value in a call to \wait,
or by blocking on an incomplete conjunct in a call to \joinandcontinue.
We attempt to minimise the former case (see Chapter \ref{chap:overlap})
and the latter case cannot occur
if the context has a spark on its local spark deque (it would run the
spark rather than block).
Therefore the large majority of the suspended contexts will not have
sparks on their deques,
and the probability of selecting a deque at random with a spark on its
stack is only a little bit higher than $M \choose N$ at best and
$M \choose 1$ at worst.
Furthermore the value of $M$ can be very high in pathological cases.
If an engine does not successfully steal a spark from a deque,
it will continue by trying to steal a spark from a different deque.
An engine can exhaust all its attempts, even when there is work
available:
a spark may be placed on a deque after the engine has already attempted
to steal from it.
Upon exhausting all its attempts or all the deques,
the engine will sleep before making another round of attempts
(see \trystealspark in Algorithm \ref{alg:try_steal_spark_initial} on
page \pageref{alg:try_steal_spark_initial}).
Each round of attempts (regardless of success or failure) has a
complexity of $O(M)$.

\plan{We associate stacks with engines}
The approach we have taken to solving these problems is based on associating
spark deques with engines rather than with contexts.
A running Mercury program has a constant number of engines,
and therefore the number of spark deques will not vary.
This allows us to remove the code used to resize the deque array,
the array is filled in when the engines are created during startup,
after which it is never modified.
This makes context creation and destruction much simpler.
It also removes the need for the lock protecting the global array of spark
deques.
We can also remove the locking code in \trystealspark
(whose original version was shown in Algorithm
\ref{alg:try_steal_spark_initial})
which was used to
ensure that the array is not changed while a thief is trying to steal a
spark.
The cost of work stealing also becomes linear in the number of engines
rather than the number of contexts.

\begin{algorithm}[tbp]
\begin{algorithmic}[1]
\Procedure{MR\_try\_steal\_spark}{}
  \If{$\left(
          \begin{array}{l}
          (current\_context \neq \text{NULL})\, \vee \\
          (MR\_num\_outstanding\_contexts < MR\_max\_contexts) \\
          \end{array}
          \right)$}
    \For{$attempt = 0$ to $MR\_num\_engines - 1$}
      \State $victim\_index \gets
          (MR\_engine.victim\_counter + attempt) \bmod MR\_num\_engines$
      \If{MR\_steal\_spark($MR\_spark\_deques$[$victim\_index$],
          \text{\code{\&}}$spark$)}
        \State $MR\_engine.victim\_counter \gets
          MR\_engine.victim\_counter + attempt$
        \State MR\_prepare\_engine\_for\_spark($spark$, NULL)
        \State \Return $spark.resume$
      \EndIf
    \EndFor
  \EndIf
  \State \Return NULL
\EndProcedure
\end{algorithmic}
\caption{try\_steal\_spark}
\label{alg:try_steal_spark_revised}
\end{algorithm}

\begin{algorithm}[tbp]
\begin{algorithmic}
\Procedure{MR\_prepare\_engine\_for\_spark}{$spark$, $join\_label$}
    \If{$current\_context = \text{NULL}$}
        \State $ctxt \gets$ MR\_get\_free\_context()
        \If{$ctxt = \text{NULL}$}
            \State $ctxt \gets$ MR\_create\_context()
        \EndIf
        \State MR\_load\_context($ctxt$)
    \EndIf
    \State $MR\_parent\_sp \gets spark.parent\_sp$
    \State $ctxt.thread\_local\_mutables \gets
      spark.thread\_local\_mutables$
    \State \Return $spark.resume$
\EndProcedure
\end{algorithmic}
\caption{MR\_prepare\_engine\_for\_spark()}
\label{alg:prepare_engine_for_spark}
\end{algorithm}

\plan{Show new \trystealspark}
We have made some other changes to \trystealspark,
whose new code is shown in Algorithm \ref{alg:try_steal_spark_revised}.
Previously \trystealspark required its caller to check that stealing a spark
would not exceed the context limit;
this check has been moved into \trystealspark (line 2).
Another change is that \trystealspark
will now call \prepareengineforspark (line 7)
which will load a context into the engine if it doesn't already have one.
(Algorithm \ref{alg:prepare_engine_for_spark}).
Finallly \trystealspark will return the address of the spark's code;
the caller will jump to this address,
if it is not NULL.

In the previous version the lock was also used to protect the victim
counter;
it ensured that round robin selection of the victim was maintained.
Now each engine independently performs its own round robin selection of the
victim using a new field \code{victim\_counter} in the engine structure.
We have not evaluated if this policy is an improvment.
However when compared with the improvement due to removing the lock and
potentially large numver of spark deques,
any difference in performance due to the selection of victims will be
negligible.
The two other changes are minor:
we have removed the configurable limit of the number of work stealing
attempts per round,
and the test for null array slots has been removed;
both are now unnecessary.

\plan{Show how this is safe.}
Associating the spark deques with engines can change the order in which
sparks are executed,
so we must ensure that the system is still deadlock free.
In the previous version,
a context that is blocked on a call to \wait may contain sparks
which can only be accessed by a thief.
In the new version,
those sparks are now associated with the engine that the context was running
on,
and therefore that engine has the opportunity to run those sparks by
retrieving them from the hot end of its own deque.
If the engine attempts to execute one of these sparks it will need a
context,
and the creation of a new context may exceed the context limit even though
the spark is being executed locally.
This is just one instance in which an engine \emph{without a context}
may try to run a spark from its own deque.
In the previous version a context would always be available because sparks
were associated with contexts.

\begin{algorithm}[tbp]
\begin{algorithmic}
    \Procedure{MR\_idle}{}
        \State $code\_ptr \gets$ MR\_try\_run\_context()
        \If{$code\_ptr \neq$ NULL}
            \Goto $code\_ptr$
        \EndIf
        \State $code\_ptr \gets$ MR\_try\_run\_local\_spark($NULL$)
        \If{$code\_ptr \neq$ NULL}
            \Goto $code\_ptr$
        \EndIf
        \State $code\_ptr \gets$ MR\_try\_steal\_spark()
        \If{$code\_ptr \neq$ NULL}
            \Goto $code\_ptr$
        \EndIf
        \Goto MR\_sleep
    \EndProcedure
\end{algorithmic}
\caption{New \idle code}
\label{alg:idle_entry_point}
\end{algorithm}

\begin{algorithm}[tbp]
\begin{algorithmic}
\Procedure{MR\_try\_run\_context}{}
    \State MR\_acquire\_lock($MR\_runqueue\_lock$)
    \State $ctxt \gets$ MR\_get\_runnable\_context()
    \State MR\_release\_lock($MR\_runqueue\_lock$)
    \If{$ctxt \neq$ NULL}
        \If{$current\_context \neq$ NULL}
            \State MR\_release\_context($current\_context$)
        \EndIf
        \State MR\_load\_context($ctxt$)
        \State $resume \gets ctxt.resume$
        \State $ctxt.resume \gets$ NULL
        \State \Return $resume$
    \Else
        \State \Return NULL
    \EndIf
\EndProcedure
\end{algorithmic}
\caption{MR\_try\_run\_context()}
\label{alg:try_run_context}
\end{algorithm}

\begin{algorithm}[tbp]
\begin{algorithmic}
\Procedure{MR\_try\_run\_local\_spark}{$join\_label$}
    \State $result \gets$ MR\_pop\_spark($this\_engine.spark\_deque$)
    \If{$result =$ NULL}
        \State \Return NULL
    \EndIf
    \If{$\left(
        \begin{array}{l}
            (current\_context \neq \text{NULL}) \wedge \\
            (join\_label \neq \text{NULL}) \wedge \\
            (spark.sync\_term.orig\_context \neq current\_context)
        \end{array}\right)$}
        \State MR\_push\_spark($this\_engine.spark\_deque$, $spark$)
        \State \Return NULL
    \EndIf
    \State MR\_prepare\_engine\_for\_spark($spark$, $join\_label$)
    \State \Return $spark.resume$
\EndProcedure
\end{algorithmic}
\caption{MR\_try\_run\_local\_spark()}
\label{alg:try_run_local_spark}
\end{algorithm}

An idle engine with a context that is free (it can be used for any spark) or
no context will call \idle to acquire new work.
\idle has changed significantly;
the new version is shown in Algorithm \ref{alg:idle_entry_point}.
Three new procedures are now used to implement the details of \idle, these
are:
\tryruncontext, \tryrunlocalspark and \trystealspark.
They are procedures so that we can use them from procedures other than
\idle, such as \joinandcontinue below.
\idle always tries to find a runnable context before a local spark;
running a spark may require creation of a context which may exceed the
context limit,
where as running a spark does not.
Furthermore,
we beleive that executing a context is optimal
as a context whose execution has already begin may make more parallel work
available by creating sparks or signalling futures.
If the engine is able to run the context until the completion of its work
(until the contexts executes the \joinandcontinue barrier at the end of a
parallel conjunct)
then this may make the context available to execute a spark from the
engine's local spark queue.
Therefore \idle always tries to run a context using \tryruncontext,
before it attempts to run a local spark using \tryrunlocalspark.
If both of these fail to find work, \idle will then attempt to steal a spark using
\trystealspark,
if this also fails then \idle will jump to \sleep (below).

\idle is a hard coded Mercury procedure and it does not return control to
its caller.
Instead it continues execution by jumping to the code address of the next
thing to execute.
such as the
the resume address of a context,
or the entry point of a spark.
When it jumps to the next thing to execute the Mercury and C stack pointers
must have the same values that they had when the control entered \idle.
This means that the C functions \tryruncontext, \tryrunlocalspark and
\trystealspark \emph{must} return
rather than making the jump themselves.
so that the C stack pointer has the same value that it did upon entering
\idle.

\tryruncontext is shown in Algorithm \ref{alg:try_run_context};
it attempts to take a context from the context runqueue while holding the
context runqueue lock.
Previously this lock protected all of \idle.
If \tryruncontext finds a context,
it first checks for and unloads the engine's current context,
and then loads the new context.
It clears the contexts resume field and then returns the field's previous
value, which \idle will jump to.

\tryrunlocalspark is shown in Algorithm \ref{alg:try_run_local_spark};
It attempts to pop a spark of the engine's deque.
If the spark deque is empty then \tryrunlocalspark
will return NULL.
If it successfully popped a spark it will
check that the engine's current context is compatible with the spark.
If incompatible \tryrunlocalspark will put the spark back on the engines
spark deque return NULL.
However when \idle calls \tryrunlocalspark the spark will always be
compatible;
we will return to this point later.
We then prepare the engine for to execute the spark using
\prepareengineforspark
(Algorithm \ref{alg:prepare_engine_for_spark}),
all this entails is making sure that the engine has a context, the context
is loaded and has the correct parent stack pointer in its parent stack
pointer register.
After this \tryrunlocalspark returns the spark's entry point to \idle which
will jump to the code address.

\begin{algorithm}[tbp]
\begin{minipage}{\textwidth}
\begin{verbatim}
struct MR_engine_sleep_sync {
    sem_t                               sleep_sem;
    lock                                lock;
    volatile unsigned                   state;
    volatile unsigned                   action;
    union MR_engine_wake_action_data    action_data;
};

union MR_engine_wake_action_data {
    MR_EngineId     worksteal_engine;
    MR_Context      *context;
};
\end{verbatim}

\begin{algorithmic}
    \Procedure{MR\_sleep}{}
        \Loop
            \State $eng\_data \gets MR\_engine\_sleep\_data$[$engine\_id$]
            \State $eng\_data.state \gets$ SLEEPING
            \State $sem\_wait(eng\_data.sleep_sem)$
            \Switch{$eng\_data.action$}
              \Case{ACTION\_SHUTDOWN}
                \State $\cdots$
              \EndCase
              \Case{ACTION\_RUN\_CONTEXT}
                \State $ctxt \gets eng\_data.action\_data.context$
                \State MR\_load\_context($ctxt$)
                \Goto $ctxt.resume\_label$
              \EndCase
              \Case{ACTION\_STEAL\_SPARK}
                \State $MR\_engine.victim\_counter \gets
                    eng\_data.action\_data.worksteal\_engine$
                \State $code\_ptr \gets$ MR\_try\_steal\_spark()
                \If{$code\_ptr \neq$ NULL}
                    \Goto $code\_ptr$
                \EndIf
                \State $code\_ptr \gets$ MR\_try\_run\_context()
                \If{$code\_ptr \neq$ NULL}
                    \Goto $code\_ptr$
                \EndIf
                \State \Break
              \EndCase
              \Case{ACTION\_NONE}
                \State $code\_ptr \gets$ MR\_try\_run\_context()
                \If{$code\_ptr \neq$ NULL}
                    \Goto $code\_ptr$
                \EndIf
                \State $code\_ptr \gets$ MR\_try\_steal\_spark()
                \If{$code\_ptr \neq$ NULL}
                    \Goto $code\_ptr$
                \EndIf
                \State \Break
              \EndCase
            \EndSwitch
        \EndLoop
    \EndProcedure
\end{algorithmic}

\end{minipage}
\caption{The \sleep code}
\end{algorithm}

\sleep is another hand written Mercury procedure.
It uses an
\enginesleepsync structure to manage the state of each engine.
These structures are organised into a global array indexed by engine ids,
making them accessible to other engines.
The structure contains a semaphore and a lock;
the engine owning the structure waits on \code{sleep\_sem} in order to
sleep,
and \code{lock} is used by other engines to control their mutual
access to the \enginesleepsync structure.
There are three other fields in the structure:
\code{state} is used by the engine that owns the structure to communicate
its state to other engines,
\code{action} and \code{action\_data} are used by other threads when
communicating to this engine.

Upon jumping into \idle an engine sets its state to \code{SLEEPING} and
waits on \code{sleep\_sem}.
If another engine posts to \code{sleep\_sem} then the engine is woken up,
and retrieves the value of the \code{action} field.
This field can be used to tell the engine what to do upon wakening.
It may be instructed to shutdown, to execute a context or to steal a spark.
If it is instructed to run a context it can be passed the context directly
using the \code{action\_data} field,
similarly, if it instructed to steal a spark \code{action\_data} will tell
it whose spark stack it should begin its round robin search from.
If thread stealing fails the engine will check the global contest queue for
a runnable context,
if that fails then \idle will loop and putting the engine back to sleep.
If no action is specified
(the value of the \code{action} field is \code{ACTION\_NONE})
them \sleep will try to run a context from the global context queue before
attempting to steal a spark.

\begin{algorithm}[tbp]
\begin{algorithmic}
\Procedure{MR\_wake\_engine}{$engine\_id, action, action\_data, states$}
    \State $eng\_data \gets MR\_engine\_sleep\_data$[$engine\_id$]
    \State MR\_acquire\_lock($eng\_data.lock$)
    \If{$eng\_data.state \in states$}
        \State $eng\_data.action \gets action$
        \State $eng\_data.action\_data \gets action\_data$
        \State $eng\_data.state \gets$ WOKEN
        \State MR\_sem\_post($eng\_data.sleep\_sem$)
        \State $result \gets$ true
    \Else
        \State $result \gets$ false
    \EndIf
    \State MR\_release\_lock($eng\_data.lock$)
    \Return $result$
\EndProcedure
\end{algorithmic}
\caption{\wakeengine}
\label{alg:wake_engine}
\end{algorithm}

Engines may be woken with a call to \wakeengine whose code is shown in
Algorithm \ref{alg:wake_engine}.
\wakeengine takes id of the engine to awaken,
the action and its data that the engine should perform upon awakening,
and the set of states that we may awaken the engine from (usually
\code{SLEEPING}).
The implementation of \wakeengine is mostly straightforward,
the important details are that we must only wake the engine if it has not
been woken already, this is done by checking the value of
\code{eng\_data.state} after acquiring the lock,
and setting the new state while holding the lock.
The action and action data must also be written to the
\enginesleepsync structure before posting to the engine's sleep
semaphore.
The parameter \code{states} is a bit field, with each state represented by
its own bit.
This is flexible, it allows us to message an engine regardless of its
current state.
For example,
we shutdown an engine by calling \wakeengine with the shutdown action a and
all bits set in the \code{states} bit field.
Compared to the previous system in which a lock and condition variable were
used,
this system allows us to wake engines selectively.
This is useful in the case when a context must be executed on a particular
engine because that engine's C stack contains a frame that made a call to
some Mercury code and now must be returned into.
In the future this feature could be used to schedule computations on
\emph{nearby} processors,
processors that may share a second or third level cache with the current
processor.

\begin{algorithm}[tbp]
\begin{algorithmic}[1]
\Procedure{MR\_join\_and\_continue}{$ST, ContLabel$}
  \State $finished \gets$ MR\_atomic\_dec\_and\_is\_zero($ST.num\_outstanding$)
  \If{$finished$}
    \If{$ST.orig\_context \neq current\_context$}
      \While{$ST.orig\_context.resume\_label \neq ContLabel$}
        \State CPU\_relax
      \EndWhile
      \State MR\_release\_context($current\_context$)
      \State $current\_context \gets$ NULL
      \State MR\_load\_context($ST.parent$)
    \EndIf
    \Goto{$ContLabel$}
  \Else
    \If{$ST.orig\_context = current\_context$}
      \State $MR\_r1 \gets ContLabel$
      \Goto{MR\_idle\_orig\_context}
    \Else
      \Goto{MR\_idle}
    \EndIf
  \EndIf
\EndProcedure
\end{algorithmic}
\caption{\joinandcontinue}
\label{alg:join_and_continue_ws2}
\end{algorithm}

By moving spark deques from contexts to engines we had to change \idle.
We have also had to change the \joinandcontinue barrier.
The new version of \joinandcontinue is shown in Algorithm
\ref{alg:join_and_continue_ws2}.
The most significant change is on line 15,
\joinandcontinue no longer attempts to run a spark from the local deque,
it relies on \idle to do this.
The second change is that \joinandcontinue no longer suspends the original
context, it executes \idle while holding the original context.
This would invalidate \idle's precondition that if an engine has a context,
that that context is otherwise free to execute \emph{any} spark,
but an original context may only execute sparks that were created by the
parallel conjunction that it is currently executing.
The new \idle code allows us to create any number of entry points,
we have created the \idleorigcontext entry point which expects to be called
with such a context.
However, since we do not set the contest's \code{resume\_label} field until
the engine has given up the context,
we must pass the value of the continuation label into \idleorigcontext.
This is done using \code{MR\_r1}, the first Mercury abstract machine
register;
this is the normal calling convention used by compiled Mercury procedures.

The other change is an optimisation on line 10.
if the parallel conjunction has been finished and this engine is not
executing the original context,
then instead of placing the original context on the context run queue as the
previous version did,
the new version unloads its current context and resumes execution of the
original context,
This has three benefits,
firstly, this does not use the run queue's lock,
making it more efficient.
Secondly, in the old algorithm, the engine would schedule the context and
call \idle,
in which it would check the context run queue and was likely to run the same
context anyway.
Thirdly, by deliberately running the context on the CPU that most
recently completed the parallel conjunction,
we may be able to take advantage of relevant data being hot in the CPU's
cache.

\begin{algorithm}[tbp]
\begin{algorithmic}
    \Procedure{MR\_idle\_orig\_context}{}
        \State $join\_label \gets MR\_r1$
        \State $code\_ptr \gets$ MR\_try\_run\_local\_spark($join\_label$)
        \If{$code\_ptr \neq$ NULL}
            \Goto $code\_ptr$
        \EndIf
        \State MR\_save\_context($ctxt$);
        \State $current\_context.resume\_label \gets join\_label$
        \State $current\_context \gets$ NULL
        \Goto MR\_idle
    \EndProcedure
\end{algorithmic}
\caption{New entry point to the idle loop for dirty contexts.}
\label{alg:idle_orig_context}
\end{algorithm}

The new entry point \idleorigcontext is shown in Algorithm
\ref{alg:idle_orig_context}.
This entry point expects to be called from \joinandcontinue while the engine
is holding a context that is needed to complete a parallel conjunction.
It tries to run a spark from the engine's local spark deque first,
the \tryrunlocalspark will check if the spark at the top of the spark deque
is compatible with the current context,
if it is not it will put the spark back onto the spark deque and return
\NULL, it also returns \NULL if there is no spark on the deque.
idleorigcontext will jump to the code address that \tryrunlocalspark returned
provided that it is non-\NULL.
Otherwise \idleorigcontext will save the corrent context,
set its \code{resume\_label} field
and jump to \idle which attempts to find work as described above.
If \idleorigcontext could not run a local spark because the spark at the top
of the deque was incompatible;
then this spark will be executed by \idle if it was not stolen by another
engine in the meantime.
We could add further entry points in the future if we found them useful,
and they do not have to jump to \idle when they finish.
For example,
it may be useful to create a special case for when an engine is known to
have a empty context;
this case could check for work in a different order and and if it does not
find any work it could jump to \sleep the way \idle currently does.

\input{tab_work_stealing_revised}

\plan{Benchmark}
\paul{XXX: There's something wrong with the prior left recursive results,
the thread safe sequential time is slower than it should be thus we get stupidly high speedups}
\paul{Also, when comparing absolute times the new work stealing code is
slower, maybe due to the order we check for work in \idle in?}

\plan{Evaluation}

\plan{Further potential work}
\plan{Steal half}
Our work stealing implementation could be improved and tuned further.
We have noticed that in many workloads such as a left recursive parallel
loop one engine creates all the sparks, all the parallelism comes from one
place.
In a situation like this work stealing becomes more common than local work
execution,
one processor would execute work locally while $P - 1$ processors act as
thieves, and a single work queue can again become a bottleneck.
To avoid this behaviour
a steal-half implementation (such as \citet{hendler:2002:stealhalf})
should quickly distributed work evenly between the processors,
reducing the overall number of work stealing operations.
\plan{memory hierarchy awareness}
Another potential improvement is in the selection of a thief's victim.
A thief may wish to prefer victims that are nearby in terms of memory
topology, so that communication of the data relevant to the spark is
cheaper.
This can also be used when selecting which engine to wake up in order to
pass work to it.
We discuss memory hierarchy awareness in more detail in the next section.

