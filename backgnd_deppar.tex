
\status{This section's content is complete.}

% This is a figure since there are a number of references to it.
\begin{figure}
\begin{verbatim}
map_foldl(M, F, L, Acc0, Acc) :-
    (
        L = [],
        Acc = Acc0
    ;
        L = [H | T],
        (
            M(H, MappedH),
            F(MappedH, Acc0, Acc1)
        &
            map_foldl(M, F, T, Acc1, Acc)
        )
    ).
\end{verbatim}
%\vspace{2mm}
\caption{Parallel \mapfoldl{}}
\label{fig:mapfoldl}
%\vspace{-1\baselineskip}
\end{figure}

\begin{figure}
\begin{verbatim}
enum MR_produced {
    MR_NOT_YET_PRODUCED, 
    MR_PRODUCED
};

struct MR_Future {
    /* lock preventing concurrent accesses */
    MercuryLock             MR_fut_lock;
    /* whether this future has been signalled yet */
    enum MR_produced        MR_fut_produced;

    /* linked list of all the contexts blocked on this future */
    MR_Context              *MR_fut_suspended;
    MR_Word                 MR_fut_value;
};
\end{verbatim}
\caption{Future data structure}
\label{fig:future}
\end{figure}

Mercury's mode system allows a conjunct in a sequential conjunction to consume
variables that are produced by conjuncts to its left, but not to its right.
However,
The first parallel execution support for Mercury
initially only supported independent AND-parallelism
\citep{conway:2002:paralle},
Communication was not allowed between conjunctions.
\citet{wang_dep_par_conj,wang_hons_thesis} relaxed this;
now parallel conjunctions have the same mode constraints as sequential
conjunctions.
Parallel conjunctions,
such as the one in Figure \ref{fig:mapfoldl},
may now
communicate through \emph{shared variables} such as \code{Acc1}.
A shared variable is a variable that is bound within the parallel
conjunction and occurs in more than one conjunct.
Recall that in Mercury,
the code location where a variable becomes bound is known
at compile time;
therefore,
shared variables can be identified at compile time.
The compiler replaces each shared variable with a \emph{future}
\citep{halstead:1984:multilisp},
which is used to safely communicate the variable's value amoung conjuncts.

Figure \ref{fig:future} shows the future data structure,
which contains room for the value of the variable,
a flag indicating whether the variable has been produced yet,
a queue of consumer contexts waiting for the value, and a mutex.
The initial value of the future has the flag set to
\code{MR\_NOT\_YET\_PRODUCED}.

Consumers call \wait when they want to retrieve a value from the future.
This acquires the lock, and if \code{MR\_fut\_produced} is 
\code{MR\_PRODUCED}, retrieves
\code{MR\_fut\_value} before releasing the lock.
If \code{MR\_fut\_produced} was \code{MR\_NOT\_YET\_PRODUCED},
then \wait will add the current context to
the list of suspended contexts before unlocking the future.
The engine will then suspend the context and look for other work.
Once the value of the future is provided,
the context will be woken up along with the others on the list of suspended
contexts.
\wait contains an optimisation:
it will check \code{MR\_fut\_produced} before
acquiring the lock as well as after.
If it is \code{MR\_PRODUCED} before the lock is acquired,
then \wait can safely retrieve the
future's value without using the lock.

A producer will call \signal to place a value into a future and wake up any
suspended contexts.
\signal will also acquire the lock to ensure that it does not race with any \wait.
\signal writes the value of the future to memory,
before it sets 
\code{MR\_fut\_produced} to \code{MR\_PRODUCED}.
These operations are separated by a memory barrier to ensure that they are
visible to other threads in this order.
After releasing the lock, \signal will schedule the suspended contexts.
Because \signal has no outputs and is deterministic,
it must be declared as impure so that the compiler will not optimise away calls
to it.

\paul{
    Discuss the alternatives of always using a wait, or waiting in other execution paths and that this is a sliding scale.
    Then describe our design decision.
    smarter algorithms require more analysis and more compilation time.
    The analysis tool should follow what the compiler does,
    and at worst it might make conservative desicions.
    Not following what the compiler does can make an error in either direction,
    the only way not to make an error is to reflect exactly what the compiler
    does.
    }

When the compiler introduces \wait and \signal operations,
it also introduces a new variable for each \wait or \signal call.
The variable represents the value of the future
either before the call to \signal or after the call to \wait.
If another goal later on the same execution path also wants to use the value of
the future, and the variable cannot be passed to it then it would have to
use an extra call to \wait.
In this instance, it is known the the value of the future is already available.
Therefore,
\get is introduced as a non thread-safe operation with lower runtime costs.
\get observes a side-effect that \wait and \signal ensures is visible.
If \wait's output is never used it might be optimised away,
and therefore \get would be unsafe when it follows a call to \wait.
\wait must therefore be impure and \get must be semipure.

To minimise waiting,
the compiler pushes \signal operations on each future
as far to the left into the producer conjunct as possible,
and it pushes \wait operations
as far to the right into each of the consumer conjuncts as possible.
This means not only pushing them
into the bodys of predicates called by the conjunct,
but also into the bodies of the predicates they call,
with the intention that on each execution path
each \signal is put immediately after
the primitive goal that produces the value of the variable,
and each \wait is put immediately before
the leftmost primitive goal that consumes the value of the variable.
Since the compiler has complete information
about which goals produce and consume which variables,
the only things that can stop the pushing process
are module boundaries and  higher order calls.
This is because
the compiler cannot push a \wait or \signal operation
into the body of a predicate that it does not have access to
or into a predicate that it can not identify.

\begin{figure}
\begin{verbatim}
map_foldl(M, F, L, Acc0, Acc) :-
    (
        L = [],
        Acc = Acc0
    ;
        L = [H | T],
        new_future(FutureAcc1),
        (
            M(H, MappedH),
            F(MappedH, Acc0, Acc1),
            signal_future(FutureAcc1, Acc1)
        &
            map_foldl_par(M, F, T, FutureAcc1, Acc)
        )
    ).

map_foldl_par(M, F, L, FutureAcc0, Acc) :-
    (
        L = [],
        wait_future(FutureAcc0, Acc0),
        Acc = Acc0
    ;
        L = [H | T],
        new_future(FutureAcc1),
        (
            M(H, MappedH),
            wait_future(FutureAcc0, Acc0),
            F(MappedH, Acc0, Acc1),
            signal_future(FutureAcc1, Acc1)
        &
            map_foldl_par(M, F, T, FutureAcc1, Acc)
        )
    ).
\end{verbatim}
%\vspace{2mm}
\caption{\mapfoldl{} with synchronisation}
\label{fig:map_foldl_sync}
%\vspace{-1\baselineskip}
\end{figure}

Given the \mapfoldl predicate in Figure~\ref{fig:mapfoldl},
this synchronisation transformation
generates the code in Figure~\ref{fig:map_foldl_sync}.


