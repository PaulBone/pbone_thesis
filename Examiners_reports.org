
Note that there may be OCR errors in this file, but I wanted it in text so I
could annotate it.

#+TAGS: clarification(c) trivial(t) bibliographic(b) diagram(p) reorder(r)
#+TAGS: discussion(d)

* TODO Examiner 1

** TODO p.28 Top.  future.wait/2                              :clarification:
   When explaining the working of future.wait/2, it would be nice to
   add a line explaining why there is no danger for deadlock.

** TODO p.30-31,  Feedback                                    :clarification:
    In your argumentation for the feedback-directed approach, you state
    yourself that a program is typically executed multiple times with
    respect to different inputs (p.31). While you use this argument in
    favour of the feedback-approach (which is imo totally justified), it
    does raise the question on how well is the feedback—approach providing a
    model for all of these runs?  Unfortunately, this question is rapidly
    put aside by your remark “Most variations in input data will not effect
    parallelisation enough to cause a significant
    difference in performance” (p.31), but this is quite strong a statement;
    is there any (experimental) proof of it?  I think the chosen approach is
    a good one.  but it should be introduced/discussed within more
    appropriate level of objectiveness. See also my remark on the discussion
    w.r.t.  Static analysis (p 92).

** DONE p 34,                                                       :trivial:
   CLOSED: [2013-03-31 Sun 18:21]
    imprecise vocabulary.  On the one hand you talk about
    “computations p and C1” but further down the test they have become
    ‘“conjuncts p and q”.

   Fixed by replacing the initial 'computations' with 'conjuncts'

** DONE p.41 Notation                                               :trivial:
   CLOSED: [2013-03-31 Sun 18:49]
   line G_{k_l},\ldots,G_{a}.  This must be G_{k+l}.

   The examiner is correct. I've fixed this.

** DONE p.50. BLKSIZE                                         :clarification:
   CLOSED: [2013-04-10 Wed 22:44]
   What is “HLKSlZE”?’ Is it some dark option to be set in the Eoehm
   runtime?  it, it should also be explained.  if care to mention you

   Maybe the examiner says that if we cannot explain it then we should
   not mention it.  I've explained that it is inscrutable.

diff --git a/rts_gc.tex b/rts_gc.tex
index a01cdf5..ba35dee 100644
--- a/rts_gc.tex
+++ b/rts_gc.tex
@@ -510,8 +510,14 @@ We anticipate that increasing the size of the local free lists will cause even
 less contention for global locks,
 allowing allocation intensive programs to have better parallel
 performance.
-The size of the local free list can be adjusted by increasing the
-\texttt{HBLKSIZE} tunable.
+We wanted to investigate if increasing the size of the local free lists could
+improve performance.
+We contacted the Boehm GC team about this and they advised us to experiment
+with the \texttt{HBLKSIZE} tunable.
+They did not say what this tunable controls.
+and it is undocumented and the source code is inscrutable.
+Our impression is that it only indirectly tunes the sizes of the local free
+lists.
 Unfortunately this feature is experimental,
 and adjusting \texttt{HBLKSIZE} caused our programs to crash.
 Therefore we cannot evaluate how \texttt{HBLKSIZE} affects our

** DONE p.60. Choice of stack                                       :reorder:
   CLOSED: [2013-04-10 Wed 22:45]
   While l was wondering for several pages Why this structure had to
   be a stack, the second half of the page provides the explanation (to
   deal with nested conjunctions).  It would help the reader if this
   justification was moved to the spot. where the stacks are introduced.

I cannot move this as there is a circular dependency in the
explanation.  I've provided a forward reference instead.  I've also
added a forward reference that was missing from an earlier chapter to
the same explanation.

diff --git a/rts_original_scheduling.tex b/rts_original_scheduling.tex
index da8adda..443d8d7 100644
--- a/rts_original_scheduling.tex
+++ b/rts_original_scheduling.tex
@@ -161,6 +161,10 @@ there are three important scenarios:
     any sparks left on the stack by $G_1$ would have been popped off by
     the \joinandcontinue barriers of the conjunctions that spawned off the
     sparks.
+    This invariant requires a \emph{last-in-first-out} storage of sparks,
+    which is why each context uses a stack rather than a queue.
+    In Section~\ref{sec:rts_work_stealing} we explain in more detail why
+    a \emph{last-in-first-out} order is important.
 
     The check that the spark's stack pointer is equal to the current
     parent stack pointer\footnote{
diff --git a/rts_work_stealing.tex b/rts_work_stealing.tex
index 2c6b9f1..3a16381 100644
--- a/rts_work_stealing.tex
+++ b/rts_work_stealing.tex
@@ -9,6 +9,7 @@ described in the previous section.
 its solution.
 In a work stealing system,
 sparks placed on a context's local spark stack
+(we describe below why we use a stack)
 are not committed to running in that context;
 they may be executed in a different context if they are stolen.
 This delays the decision of where to execute a spark until the moment

** NOOP p.71. remark
   Just a remark, but algorithm 3.8 is basic and the idea of
    reordering independent conjunctions quite seems not far.  being pushed
    very

** DONE p. 78. XXX                                                  :trivial:
   CLOSED: [2013-04-01 Mon 14:12]
   In Figure 3.6, there is an “XXX” remaining.

   Deleted, (the revisit had already been acted upon).

** DONE p.79. Busy transitions                                :clarification:
   CLOSED: [2013-04-10 Wed 21:43]
    Figure 0 = Seems strange to characterize some transitions as
    “busier” because “you think” (p.78) they occur most often.  Is
    this relevant and, if it is, could it be better (experimentally)
    validated/justified? if it isn't, don‘t talk about it as it makes
    one wonder Whether some of the made are based on
    intuitionchoicesyou only.

Described our reasoning why these edges are busier:

diff --git a/rts_work_stealing2.tex b/rts_work_stealing2.tex
index bc4178e..def8dbe 100644
--- a/rts_work_stealing2.tex
+++ b/rts_work_stealing2.tex
@@ -530,8 +530,13 @@ blue edge:
 blue denotes a transition that is done with a compare and swap on the
 \code{MR\_es\_state} field of the \enginesleepsync structure,
 whilst other transitions are made with an assignment.
-The edges drawn with thicker lines are \emph{busier}:
-these are the transitions that we think occur most often.
+The parallel runtime system is under the most load when there are a large
+number of sparks that represent small computations.
+When this occurs engines spend most of their execution time in the
+\code{MR\_WORKING}, \code{MR\_LOOKING\_FOR\_WORK} and \code{MR\_STEALING}
+states, or transitioning between them.
+Therefore these transitions are \emph{busier}
+and their edges in the graph are drawn with thicker lines.
 
 \plan{Notification transitions}
 When an engine creates a spark or makes a context runnable

** DONE p.92. Static analysis                                 :clarification:
   CLOSED: [2013-04-09 Tue 10:51]
    When (re)introducing the general approach and justifying the
    feedback-approach, the discussion on profiler-feedback versus static
    analysis could be more detailed and more objective.  You put a lot of
    emphasis on “representative input” (see also my remark concerning
    pp.30-31)that is chosen by the programmer, but i why not let the user
    decide on what is “representative input” by providing, eg. a
    specification of typical input (e.g. types and size of certain
    structures). In the latter case, an approach using static analysis might
    be more useful than a profiler—based one. Just to be clear, I 0 not
    criticising your approach, nor am I asking to change it; I am only
    stating I feel it could be somewhat more objectively (with its strong
    and weak points) introduced and discussed.

    To have this 'specification of input' you need a representative
    input, so both methods have the same requirements.  Each method
    has its own strengths and may complement the other.

diff --git a/overlap.tex b/overlap.tex
index 756d879..bde01cb 100644
--- a/overlap.tex
+++ b/overlap.tex
@@ -275,7 +275,17 @@ analysis.
 However, this will not be accurate;
 static analysis cannot take into account sizes of data terms,
 or other values that are only available at runtime.
-Therefore, we use profiler feedback information in our implementation.
+It may be possible to provide this data by some other means,
+such as by requiring the programmer to provide a specification of their
+program's likely input data.
+It has been shown that programmers are not good at estimating where their
+programs' hotspots are,
+likewise we think that a programmer's estimate of their program's likely
+input data will also be inaccurate.
+This conclusion is supported by the obvious reasoning that it is always best
+to experimentally measure something rather than estimate it is value.
+Therefore,
+our automatic parallelisation system uses profiler feedback information.
 This was introduced in Section~\ref{sec:backgnd_autopar},
 which also includes a description of Mercury's deep profiler.
 To generate the profiler feedback data,


** DONE p.93 (end of section 4.2). Terminology                      :trivial:
   CLOSED: [2013-04-01 Mon 14:52]
   Terminology: one often uses “monovariant/polyvariant” to refer to
   the fact that a predicate/procedure is
   analysed/transformed/compiled one versus multiple times with
   respect to a somewhat different content.

   I've rephrased this paragraph to use these terms (and explain
   them).

diff --git a/overlap.tex b/overlap.tex
index 97d03d0..4157fd0 100644
--- a/overlap.tex
+++ b/overlap.tex
@@ -383,11 +383,13 @@ A procedure can contain several conjunctions with two or more goals that we
 consider parallelising,
 therefore multiple candidate parallelisations may be generated for different
 conjunctions in a procedure.
-The same procedure may also appear more than once in the call graph,
-and therefore multiple parallelisations may be generated for the same
-conjunctions within the procedure.
-We discuss how we resolve conflicting recommendations for the same procedure
-in Section~\ref{sec:overlap_pragmatic}.
+The same procedure may also appear more than once in the call graph.
+Each time it occurs in the call graph its conjunctions may be parallelised
+differently, or not at all,
+therefore it is said to be \emph{polyvariant} (having multiple forms).
+Currently our implementation compiles a single \emph{monovariant} procedure,
+we discuss how the implementation chooses which candidate parallelisations to
+include in Section~\ref{sec:overlap_pragmatic}.
 
 % \section{Traversing the call graph}
 % \label{sec:overlap_dfs}

** DONE p.106 (bottom of the page):                           :clarification:
   CLOSED: [2013-04-01 Mon 17:59]
   “the recursivecalls cost at its average recursion depth is used by
   the algorithm”.  is this speaking) the best one can get or would it
   be to obtain more precise results (eg.  (theoretically possible by
   performing some finpoint computation on the predicate)?

   The examiner has understood the issue to some degree.  I've
   emphasised the issue and added discussion about getting more
   precise results through analysis of recurrence relations.

:diff --git a/conc.tex b/conc.tex
index b9e2ddc..0b49b5b 100644
--- a/conc.tex
+++ b/conc.tex
@@ -93,6 +93,7 @@ and to adjust the values that represent the costs of parallel execution
 overheads in the cost model.
 
 \section{Further work}
+\label{sec:conc_further_work}
 
 Throughout this dissertation we have discussed further work that may apply to
 each contribution.
diff --git a/overlap.tex b/overlap.tex
index a0accd5..756d879 100644
--- a/overlap.tex
+++ b/overlap.tex
@@ -1715,22 +1715,39 @@ times.
 In many cases,
 the conjunction given to Algorithm~\ref{alg:dep_par_conj_overlap_middle}
 will contain a recursive call.
-In these cases the recursive call's cost at its average recursion depth is
-used by the algorithm.
-This assumes that the recursive call
-calls the \emph{original, sequential} version of the procedure.
+In these cases the recursive call's cost at its average recursion depth in the
+sequential execution data gathered by the profiler is used by the
+algorithm.
+This is naive because it assumes that the recursive call
+calls the \emph{original, sequential} version of the procedure,
+however the call is recursive and so the parallelised procedure calls itself,
+the \emph{transformed parallel} procedure whose cost at its average recursion
+depth is going to be different from the sequential version's.
 When the recursive call calls the parallelised version,
-we can expect a similar saving (absolute time, not ratio)
+%we can expect a similar saving
+there may be a similar saving 
+(absolute time, not ratio)
 on \emph{every} recursive invocation,
 provided that there are enough free CPUs.
 How this affects the expected speedup of the top level call
 depends on the structure of the recursion.
-Our current approach handles non-recursive cases correctly,
+
+It should be possible to estimate the parallel execution time of the top level
+call into the recursive procedure,
+including the parallelism created at each level of the recursion,
+provided that
+the recursion pattern is one that is understood by the algorithms in
+Section \ref{sec:overlap_reccalls}.
+Before we implemented this it was more practical to improve the efficiency of
+recursive code
+(Chapter \ref{chap:loop_control}).
+We have not yet returned to this problem,
+see Section \ref{sec:conc_further_work}.
+Nevertheless,
+our current approach handles non-recursive cases correctly,
 which are the majority (78\%) of all cases;
 it handles a further 13\% of cases (single recursion) reasonably well
 (Section~\ref{sec:overlap_reccalls}).
-We do not currently do any further analysis when parallelising recursive
-code.
 Note that even better results for singly recursive procedures can be
 achieved because of the work in Chapter~\ref{chap:loop_control}.

** DONE p.120 (bottom of the page). Typo: “perforrned perform”.     :trivial:
   CLOSED: [2013-04-01 Mon 14:55]

   Fixed (almost) double word.

** DONE p. 12.4.  Typo: “that the each iteration”                   :trivial:
   CLOSED: [2013-04-01 Mon 14:57]

Removed 'the' from the phrase.

* TODO Examiner 2

** TODO General

*** TODO Scope outside of Mercury                                :discussion:
    I would have liked to see some discussion about how all the techniques
    proposed in this dissertation could be applied outside of Mercury
    [e.g., to Prolog? To functional languages?)

*** TODO Benchmark diversity                                     :discussion:
    Many of your considerations on two benchmarks, representing
    rely some fairly regular computations.  How would you consider
    these representatives?  Or, more in general, I would have liked to
    see a much broader pool of diverse benchmarks being used
    throughout the dissertation.

*** TODO Formal semantics                                        :discussion:
    There are no formal considerations about the fact that the
    parallel implementations respect the "theoretical" operational
    semantics of the language [e.g., same observable behavior).  Even
    though it is true, it would be a good idea to spell it out.

** TODO Chapter 1

Chapter 1 is supposed to set the contest for the whole dissertation, and it
does so in a good way. The chapter could be strengthened a bit by adding
some citations [especially in the first few pages). Additionally

*** TODO Non-SMP                                              :clarification:
    Considerations in this chapter ignore the new generations of
    architecturesbased on CUDA Numa (not SMP), etc.

*** TODO Pure/impure examples                                 :clarification:
    I would suggest to add examples of Pure and impure languages

*** CHCK Is the example in page 8 correct?

*** TODO Logic programming scope (non SLD?)                   :clarification:
    Considerations in page 9 talk about “logic programming”. but they are
    really focused on languages derived from Prolog (SLD-based, etc.).
    Logic programming is a much broader term, and the considerations in this
    page do not reach other LP languages [e.g._,ASP-based).

*** CHCK Dependent vs Independent                             :bibliographic:
    Hermenegildo used to stress that there is really no such thing as
    independent and dependent and-p, they are the same thing just seen at
    different levels of granularity [and I tend to agree with this).

    Try to find something about this in the literature, if I don't
    find anything then no action needs to be taken.

*** CHCK Research inheritance                                 :bibliographic:
    My memory might be wrong.  but the dependent and——p model of
    Pontelli and Gupta does not really build on [45] [they are
    completely independent).  Furthermore, DDAS was the name of the
    system developed by Kish Shen, not by Pontelli Gupta.

** TODO Chapter 2

*** TODO Detism stats                                         :clarification:
    Can you provide a source for the various statistics mentioned in page
    25?

*** CHCK TRO and and-parallelism                :clarification:bibliographic:
    How does the discussion in page 26 relate to some of the tail recursion
    optimizations developed for and=parallelism?

*** TODO Futures                                   :clarification:discussion:
    I might have missed it, but lots of what I see in page 28 resembles the
    behavior of conditional variables in POSIX threads.

*** TODO Evidence                                                :discussion:
    I found some considerations in page 30/31 a bit speculative (especially
    the last two paragraphs before 2.4.1); any evidence supporting these
    clairns?  @ particular, evidence related to how unbalanced Computations
    can become due to different inputs.

*** TODO Diagrams                                                   :diagram:
    The discussion in this Chapter could benefit from graphical
    representations of the data structures.

** TODO Chapter 3

*** TODO Proofread                                                  :trivial:
    I found several English errors and typos, please proofread

*** TODO Amdahl's law vs Gustafson-Barsis law      :bibliographic:discussion:
    Amdahl's law tend to be rather conservative \ have you considered
    using something like Gustafson-Barsis instead?

        [It's pesimistic for a reason - it works]

*** CHCK Clarification/Discussion (Page 50)        :clarification:discussion:
    Reason 2 page 50: would it be possible to test this hypothesis?  p)
    bounding/unbounding threads?

*** CHCK Prose on page 56
    I found page 56 rather poorly written and hard to follow.

** TODO Chapter 6

*** CHCK Please include more figures.                               :diagram:

** TODO Bibliography

Zoltan said he'd check these.

*** Several errors, please review your entries?

*** [46] has a spurious ‘p’

*** [45] appeared in a more complete forrn in some ICLP [perhaps 1994)

*** I believe Pontelli was an author in [47] -
 
*** also it was published in 2001, not in 1995; on the other hand 1995 saw
    the publication of Hernienegildo’s et al. paper on 8a:ACE (which
    introduces many of the independent and—pstructures and optimizations)

*** [90] was published in ICl_.P’97


